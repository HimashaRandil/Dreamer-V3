{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\github_clone\\\\Dreamer-V3'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('../')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ernest\\.conda\\envs\\l2rpn-test\\lib\\site-packages\\grid2op\\Backend\\pandaPowerBackend.py:36: UserWarning: Numba cannot be loaded. You will gain possibly massive speed if installing it by \n",
      "\tc:\\Users\\Ernest\\.conda\\envs\\l2rpn-test\\python.exe -m pip install numba\n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import torch\n",
    "from dreamer.modules.worldModel import WorldModel, Trainer\n",
    "from dreamer.Utils.utils import Config\n",
    "from torch.utils.data import DataLoader\n",
    "from dreamer.Utils.dataset import GrdiDataset, load_npz_files_from_folder, LazyGrdiBatchLoader\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config.from_yaml('config.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda is availabel for Training\n",
      "Model loaded successfully from dreamer\\models\\recurrent_model\n",
      "Model loaded successfully from dreamer\\models\\encoder\n",
      "Model loaded successfully from dreamer\\models\\dynamic_predictor\n",
      "Model loaded successfully from dreamer\\models\\decoder\n",
      "Model loaded successfully from dreamer\\models\\reward_predictor\n",
      "Model loaded successfully from dreamer\\models\\continue_predictor\n",
      "World model loaded at dreamer\\models\n"
     ]
    }
   ],
   "source": [
    "wm = WorldModel(config=config)\n",
    "wm.load_world_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"C:\\\\Users\\\\Ernest\\\\Downloads\\\\topo_data\" \n",
    "observations, rewards, actions, dones, next_observations = load_npz_files_from_folder(folder_path, start=30, end=35)\n",
    "batch_size = 32  # You can adjust this based on your requirements\n",
    "dataset = GrdiDataset(observations, rewards, actions, dones, next_observations, device=wm.device)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(config=config, model=wm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train(data_loader=dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Total Loss = 6.0233, Avg Recon Loss = 5.2455, Avg Reward Loss = 0.0499, Avg Continue Loss = 0.7268, Avg Dynamic KL Loss = 567.1021, \n"
     ]
    }
   ],
   "source": [
    "trainer.evaluate(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MARL2023paper_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
