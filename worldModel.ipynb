{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ernest\\.conda\\envs\\l2rpn-test\\lib\\site-packages\\grid2op\\Backend\\pandaPowerBackend.py:36: UserWarning: Numba cannot be loaded. You will gain possibly massive speed if installing it by \n",
      "\tc:\\Users\\Ernest\\.conda\\envs\\l2rpn-test\\python.exe -m pip install numba\n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import torch\n",
    "from dreamer.modules.worldModel import WorldModel, Trainer\n",
    "from dreamer.Utils.utils import Config\n",
    "from torch.utils.data import DataLoader\n",
    "from dreamer.Utils.dataset import GrdiDataset, load_npz_files_from_folder\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config.from_yaml('config.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda is availabel for Training\n"
     ]
    }
   ],
   "source": [
    "wm = WorldModel(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'dreamer\\\\data_generation\\\\temp' \n",
    "observations, rewards, actions, dones, next_observations = load_npz_files_from_folder(folder_path)\n",
    "batch_size = 32  # You can adjust this based on your requirements\n",
    "dataset = GrdiDataset(observations, rewards, actions, dones, next_observations, device=wm.device)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(config=config, model=wm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss of 1: 7.035431308754944e+17, Recon Loss: 108533269921792.0, Reward Loss: 1507880320.0, Continue Loss: 0.7738044261932373, Dynamic KL Loss: 3.517172990413583e+19, Representation loss : 3.517172990413583e+19\n",
      "Total Loss of 2: 4.444530289313579e+18, Recon Loss: 112079864332288.0, Reward Loss: 8140670976.0, Continue Loss: 0.7587900757789612, Dynamic KL Loss: 2.2222090530710985e+20, Representation loss : 2.2222090530710985e+20\n",
      "Total Loss of 3: 4.701240800705092e+19, Recon Loss: 861138325602304.0, Reward Loss: 1915609153536.0, Continue Loss: 0.812561571598053, Dynamic KL Loss: 2.3505774050498534e+21, Representation loss : 2.3505774050498534e+21\n",
      "Total Loss of 4: 4.53967790241271e+18, Recon Loss: 3839920611262464.0, Reward Loss: 27954974720.0, Continue Loss: 0.6919258236885071, Dynamic KL Loss: 2.267919005992165e+20, Representation loss : 2.267919005992165e+20\n",
      "Total Loss of 5: 3.919380721021485e+19, Recon Loss: 799089201512448.0, Reward Loss: 1789128867840.0, Continue Loss: 0.6919258236885071, Dynamic KL Loss: 1.9596503206953054e+21, Representation loss : 1.9596503206953054e+21\n",
      "Total Loss of 6: 4.963384466341888e+17, Recon Loss: 6037795504128.0, Reward Loss: 267922432.0, Continue Loss: 0.8125615119934082, Dynamic KL Loss: 2.4816621752718197e+19, Representation loss : 2.4816621752718197e+19\n",
      "Total Loss of 7: 2.5779549056794624e+16, Recon Loss: 5266378063872.0, Reward Loss: 2954304512.0, Continue Loss: 0.7156686782836914, Dynamic KL Loss: 1.2887139394162524e+18, Representation loss : 1.2887139394162524e+18\n",
      "Total Loss of 8: 8.732101445471437e+17, Recon Loss: 105115289649152.0, Reward Loss: 1057589760.0, Continue Loss: 0.7425544261932373, Dynamic KL Loss: 4.3655255959822926e+19, Representation loss : 4.3655255959822926e+19\n",
      "Total Loss of 9: 7.568466814959616e+16, Recon Loss: 11664114057216.0, Reward Loss: 250458685440.0, Continue Loss: 0.708161473274231, Dynamic KL Loss: 3.7836377642353295e+18, Representation loss : 3.7836377642353295e+18\n",
      "Total Loss of 10: 1.9262630080030966e+18, Recon Loss: 199810736979968.0, Reward Loss: 2687666688.0, Continue Loss: 0.7469186782836914, Dynamic KL Loss: 9.630316243652811e+19, Representation loss : 9.630316243652811e+19\n",
      "Total Loss of 11: 1.5299952350326266e+20, Recon Loss: 1.5448022406135808e+16, Reward Loss: 34526791204864.0, Continue Loss: 0.8631901741027832, Dynamic KL Loss: 7.649202400452156e+21, Representation loss : 7.649202400452156e+21\n",
      "Total Loss of 12: 1.918418872148217e+19, Recon Loss: 478832314286080.0, Reward Loss: 741822889984.0, Continue Loss: 0.7888187170028687, Dynamic KL Loss: 9.591854447303904e+20, Representation loss : 9.591854447303904e+20\n",
      "Total Loss of 13: 1.2045976715030168e+19, Recon Loss: 5279819403100160.0, Reward Loss: 22413387776.0, Continue Loss: 0.8050544261932373, Dynamic KL Loss: 6.020348649999119e+20, Representation loss : 6.020348649999119e+20\n",
      "Total Loss of 14: 2.439738777875251e+16, Recon Loss: 937168207872.0, Reward Loss: 1251905792.0, Continue Loss: 0.8244329690933228, Dynamic KL Loss: 1.219822526549459e+18, Representation loss : 1.219822526549459e+18\n",
      "Total Loss of 15: 2.226486582112682e+18, Recon Loss: 422325409284096.0, Reward Loss: 910039449600.0, Continue Loss: 0.6488044261932373, Dynamic KL Loss: 1.113031750516715e+20, Representation loss : 1.113031750516715e+20\n",
      "Total Loss of 16: 1.4655665364533248e+18, Recon Loss: 676518216859648.0, Reward Loss: 1987787008.0, Continue Loss: 0.770661473274231, Dynamic KL Loss: 7.324449924792608e+19, Representation loss : 7.324449924792608e+19\n",
      "Total Loss of 17: 2.8510772876908954e+17, Recon Loss: 180496185163776.0, Reward Loss: 1223770880.0, Continue Loss: 0.7200329303741455, Dynamic KL Loss: 1.4246362265488982e+19, Representation loss : 1.4246362265488982e+19\n",
      "Total Loss of 18: 1.3239142200639488e+16, Recon Loss: 1928303345664.0, Reward Loss: 4749154304.0, Continue Loss: 0.8050544261932373, Dynamic KL Loss: 6.618605076275528e+17, Representation loss : 6.618605076275528e+17\n",
      "Total Loss of 19: 7.341175255869686e+17, Recon Loss: 223875069640704.0, Reward Loss: 437375827968.0, Continue Loss: 0.7931829690933228, Dynamic KL Loss: 3.669466345976837e+19, Representation loss : 3.669466345976837e+19\n",
      "Total Loss of 20: 4900957116694528.0, Recon Loss: 572917415936.0, Reward Loss: 71340416.0, Continue Loss: 0.750061571598053, Dynamic KL Loss: 2.4501920840286208e+17, Representation loss : 2.4501920840286208e+17\n",
      "Total Loss of 21: 3307954283479040.0, Recon Loss: 346278035456.0, Reward Loss: 6552955904.0, Continue Loss: 0.7469186782836914, Dynamic KL Loss: 1.653800865544274e+17, Representation loss : 1.653800865544274e+17\n",
      "Total Loss of 22: 5.890933712484303e+18, Recon Loss: 1015163167703040.0, Reward Loss: 3391738880.0, Continue Loss: 0.7037972211837769, Dynamic KL Loss: 2.9449593876454677e+20, Representation loss : 2.9449593876454677e+20\n",
      "Total Loss of 23: 1.136980922466304e+16, Recon Loss: 855735074816.0, Reward Loss: 1809988864.0, Continue Loss: 0.7306829690933228, Dynamic KL Loss: 5.684476146394071e+17, Representation loss : 5.684476146394071e+17\n",
      "Total Loss of 24: 9.167712559233499e+18, Recon Loss: 4112400852713472.0, Reward Loss: 14667548672.0, Continue Loss: 0.6994329690933228, Dynamic KL Loss: 4.581800060931413e+20, Representation loss : 4.581800060931413e+20\n",
      "Total Loss of 25: 5686524351873024.0, Recon Loss: 780125536256.0, Reward Loss: 563969792.0, Continue Loss: 0.7306829690933228, Dynamic KL Loss: 2.8428718385712333e+17, Representation loss : 2.8428718385712333e+17\n",
      "Total Loss of 26: 8.688857103395193e+18, Recon Loss: 2500063418908672.0, Reward Loss: 727216488448.0, Continue Loss: 0.8481758236885071, Dynamic KL Loss: 4.343178242050071e+20, Representation loss : 4.343178242050071e+20\n",
      "Total Loss of 27: 1.7151512779119657e+18, Recon Loss: 121120023904256.0, Reward Loss: 240337010688.0, Continue Loss: 0.812561571598053, Dynamic KL Loss: 8.575150118848273e+19, Representation loss : 8.575150118848273e+19\n",
      "Total Loss of 28: 7974959699722240.0, Recon Loss: 616702017536.0, Reward Loss: 485076992.0, Continue Loss: 0.7425544261932373, Dynamic KL Loss: 3.987171385309921e+17, Representation loss : 3.987171385309921e+17\n",
      "Total Loss of 29: 6993818444365824.0, Recon Loss: 682781179904.0, Reward Loss: 553679744.0, Continue Loss: 0.8244329690933228, Dynamic KL Loss: 3.496567579009352e+17, Representation loss : 3.496567579009352e+17\n",
      "Total Loss of 30: 1.3008592651157504e+16, Recon Loss: 829365682176.0, Reward Loss: 106807184.0, Continue Loss: 0.7425544261932373, Dynamic KL Loss: 6.503881345838612e+17, Representation loss : 6.503881345838612e+17\n",
      "Total Loss of 31: 1.4340035433495265e+18, Recon Loss: 985042427838464.0, Reward Loss: 7118368768.0, Continue Loss: 0.718811571598053, Dynamic KL Loss: 7.1650928667278705e+19, Representation loss : 7.1650928667278705e+19\n",
      "Total Loss of 32: 1.1053002816183337e+18, Recon Loss: 170764460359680.0, Reward Loss: 255049940992.0, Continue Loss: 0.7275400757789612, Dynamic KL Loss: 5.525646702727817e+19, Representation loss : 5.525646702727817e+19\n",
      "Total Loss of 33: 7.690189273632761e+19, Recon Loss: 719590631931904.0, Reward Loss: 992353189888.0, Continue Loss: 0.812561571598053, Dynamic KL Loss: 3.8450585200584315e+21, Representation loss : 3.8450585200584315e+21\n",
      "Total Loss of 34: 3.2732601896379875e+19, Recon Loss: 2.4340088620056576e+16, Reward Loss: 73883680768.0, Continue Loss: 0.7469186782836914, Dynamic KL Loss: 1.6354131025728132e+21, Representation loss : 1.6354131025728132e+21\n",
      "Total Loss of 35: 3216458326736896.0, Recon Loss: 336623108096.0, Reward Loss: 1082118784.0, Continue Loss: 0.781311571598053, Dynamic KL Loss: 1.608060322835333e+17, Representation loss : 1.608060322835333e+17\n",
      "Total Loss of 36: 9.678252311795938e+19, Recon Loss: 6.224296240637542e+16, Reward Loss: 189721100288.0, Continue Loss: 0.8363044261932373, Dynamic KL Loss: 4.836014256516386e+21, Representation loss : 4.836014256516386e+21\n",
      "Total Loss of 37: 4.729395335250575e+18, Recon Loss: 1944082989449216.0, Reward Loss: 691297845248.0, Continue Loss: 0.7619329690933228, Dynamic KL Loss: 2.3637251715807524e+20, Representation loss : 2.3637251715807524e+20\n",
      "Total Loss of 38: 1.6553413844140032e+16, Recon Loss: 4294063947776.0, Reward Loss: 252150240.0, Continue Loss: 0.8200687170028687, Dynamic KL Loss: 8.274559610220708e+17, Representation loss : 8.274559610220708e+17\n",
      "Total Loss of 39: 1.469756062302208e+16, Recon Loss: 2236981968896.0, Reward Loss: 2309387264.0, Continue Loss: 0.6800544261932373, Dynamic KL Loss: 7.34766100008403e+17, Representation loss : 7.34766100008403e+17\n",
      "Total Loss of 40: 2050543820210176.0, Recon Loss: 455539752960.0, Reward Loss: 718647936.0, Continue Loss: 0.7587900757789612, Dynamic KL Loss: 1.0250438527103795e+17, Representation loss : 1.0250438527103795e+17\n",
      "Total Loss of 41: 1.8454329604429578e+18, Recon Loss: 1092050665603072.0, Reward Loss: 680566915072.0, Continue Loss: 0.7738044261932373, Dynamic KL Loss: 9.221700779180556e+19, Representation loss : 9.221700779180556e+19\n",
      "Total Loss of 42: 2.1029501285401887e+19, Recon Loss: 1023334208765952.0, Reward Loss: 7915035648.0, Continue Loss: 0.7931829690933228, Dynamic KL Loss: 1.0514238798047981e+21, Representation loss : 1.0514238798047981e+21\n",
      "Total Loss of 43: 5.80562686589272e+17, Recon Loss: 90483913129984.0, Reward Loss: 10193634304.0, Continue Loss: 0.7350472211837769, Dynamic KL Loss: 2.9023608327286817e+19, Representation loss : 2.9023608327286817e+19\n",
      "Total Loss of 44: 7.229925294981775e+17, Recon Loss: 116660975435776.0, Reward Loss: 400603232.0, Continue Loss: 0.8394473195075989, Dynamic KL Loss: 3.6143797139136315e+19, Representation loss : 3.6143797139136315e+19\n",
      "Total Loss of 45: 1.1444797635664282e+17, Recon Loss: 13926336036864.0, Reward Loss: 5095287808.0, Continue Loss: 0.7587900757789612, Dynamic KL Loss: 5.72170238029516e+18, Representation loss : 5.72170238029516e+18\n",
      "Total Loss of 46: 1.4347683361500168e+19, Recon Loss: 247688297709568.0, Reward Loss: 74777206784.0, Continue Loss: 0.7575687170028687, Dynamic KL Loss: 7.173718403506378e+20, Representation loss : 7.173718403506378e+20\n",
      "Total Loss of 47: 7.981657271723622e+18, Recon Loss: 1.3969271608573952e+16, Reward Loss: 1086081280.0, Continue Loss: 0.7738044261932373, Dynamic KL Loss: 3.9838441201877595e+20, Representation loss : 3.9838441201877595e+20\n",
      "Total Loss of 48: 4.415226105410093e+18, Recon Loss: 51972157734912.0, Reward Loss: 12426868736.0, Continue Loss: 0.8363044261932373, Dynamic KL Loss: 2.2075871317184217e+20, Representation loss : 2.2075871317184217e+20\n",
      "Total Loss of 49: 3.968810571918213e+17, Recon Loss: 76178492751872.0, Reward Loss: 375220672.0, Continue Loss: 0.7037972211837769, Dynamic KL Loss: 1.9840245319543554e+19, Representation loss : 1.9840245319543554e+19\n",
      "Total Loss of 50: 3.0483021429735424e+16, Recon Loss: 2615672307712.0, Reward Loss: 3942575360.0, Continue Loss: 0.812561571598053, Dynamic KL Loss: 1.5240201479986872e+18, Representation loss : 1.5240201479986872e+18\n",
      "Total Loss of 51: 5120794480869376.0, Recon Loss: 1828714184704.0, Reward Loss: 375164288.0, Continue Loss: 0.7425544261932373, Dynamic KL Loss: 2.559482680836096e+17, Representation loss : 2.559482680836096e+17\n",
      "Total Loss of 52: 6.548887105542554e+17, Recon Loss: 44654028390400.0, Reward Loss: 6612166656.0, Continue Loss: 0.6606758236885071, Dynamic KL Loss: 3.2742202831913615e+19, Representation loss : 3.2742202831913615e+19\n",
      "Total Loss of 53: 2.0715778319843328e+17, Recon Loss: 10196054179840.0, Reward Loss: 926227328.0, Continue Loss: 0.7037972211837769, Dynamic KL Loss: 1.035737974244062e+19, Representation loss : 1.035737974244062e+19\n",
      "Total Loss of 54: 2.5495222221799424e+16, Recon Loss: 2588750643200.0, Reward Loss: 519459296.0, Continue Loss: 0.7619329690933228, Dynamic KL Loss: 1.2746318068045578e+18, Representation loss : 1.2746318068045578e+18\n",
      "Total Loss of 55: 7.154678155150623e+17, Recon Loss: 694882336768.0, Reward Loss: 169696800.0, Continue Loss: 0.750061571598053, Dynamic KL Loss: 3.5773358477599048e+19, Representation loss : 3.5773358477599048e+19\n",
      "Total Loss of 56: 2.7968457664364544e+17, Recon Loss: 1717777203200.0, Reward Loss: 564399168.0, Continue Loss: 0.843811571598053, Dynamic KL Loss: 1.3984143035915567e+19, Representation loss : 1.3984143035915567e+19\n",
      "Total Loss of 57: 366904023711744.0, Recon Loss: 43261378560.0, Reward Loss: 103879384.0, Continue Loss: 0.8169258236885071, Dynamic KL Loss: 1.834303222710272e+16, Representation loss : 1.834303222710272e+16\n",
      "Total Loss of 58: 4818386370428928.0, Recon Loss: 1509166678016.0, Reward Loss: 846638144.0, Continue Loss: 0.7469186782836914, Dynamic KL Loss: 2.408438301762519e+17, Representation loss : 2.408438301762519e+17\n",
      "Total Loss of 59: 8.229311957958656e+16, Recon Loss: 4634631995392.0, Reward Loss: 7057816576.0, Continue Loss: 0.7975472211837769, Dynamic KL Loss: 4.1144241881842975e+18, Representation loss : 4.1144241881842975e+18\n",
      "Total Loss of 60: 9.127630137720832e+17, Recon Loss: 4348152643584.0, Reward Loss: 437664256.0, Continue Loss: 0.8169258236885071, Dynamic KL Loss: 4.56379305114007e+19, Representation loss : 4.56379305114007e+19\n",
      "Total Loss of 61: 9070349232635904.0, Recon Loss: 4571823341568.0, Reward Loss: 38954504.0, Continue Loss: 0.781311571598053, Dynamic KL Loss: 4.53288889914753e+17, Representation loss : 4.53288889914753e+17\n",
      "Total Loss of 62: 4389707295227904.0, Recon Loss: 6280396668928.0, Reward Loss: 30869588.0, Continue Loss: 0.8169258236885071, Dynamic KL Loss: 2.1917135648115917e+17, Representation loss : 2.1917135648115917e+17\n",
      "Total Loss of 63: 4.824372695846093e+16, Recon Loss: 2730615635968.0, Reward Loss: 810936000.0, Continue Loss: 0.8050544261932373, Dynamic KL Loss: 2.412049785142903e+18, Representation loss : 2.412049785142903e+18\n",
      "Total Loss of 64: 2.838395314417697e+18, Recon Loss: 492453903728640.0, Reward Loss: 26947294.0, Continue Loss: 0.7662972211837769, Dynamic KL Loss: 1.4189515095407382e+20, Representation loss : 1.4189515095407382e+20\n",
      "Total Loss of 65: 3.1705877388606833e+18, Recon Loss: 1285551223209984.0, Reward Loss: 4962993664.0, Continue Loss: 0.6962900757789612, Dynamic KL Loss: 1.5846511664009996e+20, Representation loss : 1.5846511664009996e+20\n",
      "Total Loss of 66: 3.676291894259745e+18, Recon Loss: 51766200631296.0, Reward Loss: 1989726848.0, Continue Loss: 0.8556829690933228, Dynamic KL Loss: 1.838120086616387e+20, Representation loss : 1.838120086616387e+20\n",
      "Total Loss of 67: 6.273192725315584e+16, Recon Loss: 156460105334784.0, Reward Loss: 828968320.0, Continue Loss: 0.750061571598053, Dynamic KL Loss: 3.128773311656362e+18, Representation loss : 3.128773311656362e+18\n",
      "Total Loss of 68: 3.062679303760747e+19, Recon Loss: 3347027480018944.0, Reward Loss: 70978027520.0, Continue Loss: 0.7975472211837769, Dynamic KL Loss: 1.5311723633852306e+21, Representation loss : 1.5311723633852306e+21\n",
      "Total Loss of 69: 1.2214697324068209e+18, Recon Loss: 501364987789312.0, Reward Loss: 425516064.0, Continue Loss: 0.7975472211837769, Dynamic KL Loss: 6.104842160351845e+19, Representation loss : 6.104842160351845e+19\n",
      "Total Loss of 70: 8.764204608022118e+16, Recon Loss: 2118967099392.0, Reward Loss: 3204501248.0, Continue Loss: 0.718811571598053, Dynamic KL Loss: 4.38199639011754e+18, Representation loss : 4.38199639011754e+18\n",
      "Total Loss of 71: 5.86401107076658e+18, Recon Loss: 710628511580160.0, Reward Loss: 11984504832.0, Continue Loss: 0.6606758236885071, Dynamic KL Loss: 2.9316501952154252e+20, Representation loss : 2.9316501952154252e+20\n",
      "Total Loss of 72: 1.0544341206433792e+16, Recon Loss: 2609684414464.0, Reward Loss: 438821120.0, Continue Loss: 0.8200687170028687, Dynamic KL Loss: 5.270865641828516e+17, Representation loss : 5.270865641828516e+17\n",
      "Total Loss of 73: 5.141425223131726e+18, Recon Loss: 467243150344192.0, Reward Loss: 4138058240.0, Continue Loss: 0.8050544261932373, Dynamic KL Loss: 2.570479097286356e+20, Representation loss : 2.570479097286356e+20\n",
      "Total Loss of 74: 1.8455433239225958e+18, Recon Loss: 53312829259776.0, Reward Loss: 1784356608.0, Continue Loss: 0.8394472599029541, Dynamic KL Loss: 9.227449905579871e+19, Representation loss : 9.227449905579871e+19\n",
      "Total Loss of 75: 1.1261497158844547e+20, Recon Loss: 2.2649387628888064e+16, Reward Loss: 12400029696.0, Continue Loss: 0.8438115119934082, Dynamic KL Loss: 5.629616064853478e+21, Representation loss : 5.629616064853478e+21\n",
      "Total Loss of 76: 4.958714118904218e+16, Recon Loss: 2150259621888.0, Reward Loss: 94204528.0, Continue Loss: 0.8006901741027832, Dynamic KL Loss: 2.4792497368093164e+18, Representation loss : 2.4792497368093164e+18\n",
      "Total Loss of 77: 1.1555875797860352e+17, Recon Loss: 7255463297024.0, Reward Loss: 165748128.0, Continue Loss: 0.781311571598053, Dynamic KL Loss: 5.777575163172225e+18, Representation loss : 5.777575163172225e+18\n",
      "Total Loss of 78: 1.2296245352721285e+19, Recon Loss: 4.540313437313434e+16, Reward Loss: 14716047360.0, Continue Loss: 0.750061571598053, Dynamic KL Loss: 6.125421147742882e+20, Representation loss : 6.125421147742882e+20\n",
      "Total Loss of 79: 1.6762996222276403e+17, Recon Loss: 42770957860864.0, Reward Loss: 405877440.0, Continue Loss: 0.7156686782836914, Dynamic KL Loss: 8.379359423583224e+18, Representation loss : 8.379359423583224e+18\n",
      "Total Loss of 80: 2.2095420633926074e+19, Recon Loss: 9573286681772032.0, Reward Loss: 1925945856.0, Continue Loss: 0.7306829690933228, Dynamic KL Loss: 1.1042923395179421e+21, Representation loss : 1.1042923395179421e+21\n",
      "Total Loss of 81: 9764711226671104.0, Recon Loss: 958521344000.0, Reward Loss: 792855552.0, Continue Loss: 0.7231758236885071, Dynamic KL Loss: 4.8818762949853184e+17, Representation loss : 4.8818762949853184e+17\n",
      "Total Loss of 82: 1.5449317338775552e+16, Recon Loss: 1367330914304.0, Reward Loss: 89819568.0, Continue Loss: 0.7694401741027832, Dynamic KL Loss: 7.723975039443272e+17, Representation loss : 7.723975039443272e+17\n",
      "Total Loss of 83: 1.0838128351143526e+17, Recon Loss: 27423162761216.0, Reward Loss: 106926696.0, Continue Loss: 0.645661473274231, Dynamic KL Loss: 5.417693462529049e+18, Representation loss : 5.417693462529049e+18\n",
      "Total Loss of 84: 3.0385729511264092e+19, Recon Loss: 2.6968986562330624e+16, Reward Loss: 670037760.0, Continue Loss: 0.7544258236885071, Dynamic KL Loss: 1.5179381136677373e+21, Representation loss : 1.5179381136677373e+21\n",
      "Total Loss of 85: 3.763586960240044e+19, Recon Loss: 1831607862296576.0, Reward Loss: 663023424.0, Continue Loss: 0.7781686782836914, Dynamic KL Loss: 1.8817018776072885e+21, Representation loss : 1.8817018776072885e+21\n",
      "Total Loss of 86: 5.07863376333688e+18, Recon Loss: 1188131969695744.0, Reward Loss: 1359690496.0, Continue Loss: 0.8050544261932373, Dynamic KL Loss: 2.5387229144919992e+20, Representation loss : 2.5387229144919992e+20\n",
      "Total Loss of 87: 2.2447124304520806e+17, Recon Loss: 5686741172224.0, Reward Loss: 80360480.0, Continue Loss: 0.7231758236885071, Dynamic KL Loss: 1.1223278134663053e+19, Representation loss : 1.1223278134663053e+19\n",
      "Total Loss of 88: 2.5946598373798707e+17, Recon Loss: 153680556851200.0, Reward Loss: 378054848.0, Continue Loss: 0.7619329690933228, Dynamic KL Loss: 1.296561483757178e+19, Representation loss : 1.296561483757178e+19\n",
      "Total Loss of 89: 4.194730593331708e+18, Recon Loss: 716270219558912.0, Reward Loss: 316016160.0, Continue Loss: 0.6919258236885071, Dynamic KL Loss: 2.0970072242115943e+20, Representation loss : 2.0970072242115943e+20\n",
      "Total Loss of 90: 1.319634955168383e+19, Recon Loss: 290440586723328.0, Reward Loss: 942757312.0, Continue Loss: 0.8050544261932373, Dynamic KL Loss: 6.598029596326583e+20, Representation loss : 6.598029596326583e+20\n",
      "Total Loss of 91: 5615452843671552.0, Recon Loss: 550111346688.0, Reward Loss: 1002810304.0, Continue Loss: 0.875061571598053, Dynamic KL Loss: 2.8074510714824294e+17, Representation loss : 2.8074510714824294e+17\n",
      "Total Loss of 92: 1.0407547571798016e+16, Recon Loss: 4806028034048.0, Reward Loss: 190317056.0, Continue Loss: 0.7350472211837769, Dynamic KL Loss: 5.201371009394934e+17, Representation loss : 5.201371009394934e+17\n",
      "Total Loss of 93: 9.763003547674214e+17, Recon Loss: 2380003016704.0, Reward Loss: 328372608.0, Continue Loss: 0.7037972211837769, Dynamic KL Loss: 4.881490338916178e+19, Representation loss : 4.881490338916178e+19\n",
      "Total Loss of 94: 7.84385582301184e+16, Recon Loss: 18580420689920.0, Reward Loss: 171316816.0, Continue Loss: 0.7650759220123291, Dynamic KL Loss: 3.9209992021375713e+18, Representation loss : 3.9209992021375713e+18\n",
      "Total Loss of 95: 4.425596754058858e+19, Recon Loss: 2433471024726016.0, Reward Loss: 6017658368.0, Continue Loss: 0.8081972599029541, Dynamic KL Loss: 2.2126769029847921e+21, Representation loss : 2.2126769029847921e+21\n",
      "Total Loss of 96: 1.616809171217285e+17, Recon Loss: 8292204019712.0, Reward Loss: 97671664.0, Continue Loss: 0.7231758236885071, Dynamic KL Loss: 8.083631477641708e+18, Representation loss : 8.083631477641708e+18\n",
      "Total Loss of 97: 6.500932936689254e+16, Recon Loss: 26961288101888.0, Reward Loss: 1035876544.0, Continue Loss: 0.718811571598053, Dynamic KL Loss: 3.2491184327292355e+18, Representation loss : 3.2491184327292355e+18\n",
      "Total Loss of 98: 1.736811760058368e+17, Recon Loss: 10893574275072.0, Reward Loss: 256263280.0, Continue Loss: 0.6950687170028687, Dynamic KL Loss: 8.683514026640015e+18, Representation loss : 8.683514026640015e+18\n",
      "Total Loss of 99: 2.085333409642578e+17, Recon Loss: 13894890291200.0, Reward Loss: 894356864.0, Continue Loss: 0.7544258236885071, Dynamic KL Loss: 1.0425972775339426e+19, Representation loss : 1.0425972775339426e+19\n",
      "Total Loss of 100: 8474770949537792.0, Recon Loss: 3154202329088.0, Reward Loss: 926304320.0, Continue Loss: 0.7544258236885071, Dynamic KL Loss: 4.235808072867512e+17, Representation loss : 4.235808072867512e+17\n",
      "Total Loss of 101: 1.7357976323804365e+18, Recon Loss: 98352544874496.0, Reward Loss: 80567072.0, Continue Loss: 0.7931829690933228, Dynamic KL Loss: 8.678496295375497e+19, Representation loss : 8.678496295375497e+19\n",
      "Total Loss of 102: 1.672764005149573e+18, Recon Loss: 13823784255488.0, Reward Loss: 1811704064.0, Continue Loss: 0.718811571598053, Dynamic KL Loss: 8.363750976417641e+19, Representation loss : 8.363750976417641e+19\n",
      "Total Loss of 103: 1.2302866611743752e+19, Recon Loss: 1675105159610368.0, Reward Loss: 2355868160.0, Continue Loss: 0.7425544261932373, Dynamic KL Loss: 6.150595565972441e+20, Representation loss : 6.150595565972441e+20\n",
      "Total Loss of 104: 1.1733436188327936e+16, Recon Loss: 2212222468096.0, Reward Loss: 2618603776.0, Continue Loss: 0.7738044261932373, Dynamic KL Loss: 5.865611409940808e+17, Representation loss : 5.865611409940808e+17\n",
      "Total Loss of 105: 1.6579923413083095e+18, Recon Loss: 10500155899904.0, Reward Loss: 449289152.0, Continue Loss: 0.7619329690933228, Dynamic KL Loss: 8.28990953471481e+19, Representation loss : 8.28990953471481e+19\n",
      "Total Loss of 106: 8.864240752897556e+18, Recon Loss: 289835600314368.0, Reward Loss: 115227552.0, Continue Loss: 0.8275759220123291, Dynamic KL Loss: 4.4319755047967025e+20, Representation loss : 4.4319755047967025e+20\n",
      "Total Loss of 107: 1.9401447460306944e+16, Recon Loss: 2832411656192.0, Reward Loss: 57375784.0, Continue Loss: 0.8050544261932373, Dynamic KL Loss: 9.699308151882383e+17, Representation loss : 9.699308151882383e+17\n",
      "Total Loss of 108: 2.4442017041623286e+18, Recon Loss: 247574648848384.0, Reward Loss: 963340736.0, Continue Loss: 0.718811571598053, Dynamic KL Loss: 1.2219769920962953e+20, Representation loss : 1.2219769920962953e+20\n",
      "Total Loss of 109: 6.007520427935531e+18, Recon Loss: 17713944592384.0, Reward Loss: 4159345920.0, Continue Loss: 0.7231758236885071, Dynamic KL Loss: 3.003751417874743e+20, Representation loss : 3.003751417874743e+20\n",
      "Total Loss of 110: 5.782801519896166e+16, Recon Loss: 19257421201408.0, Reward Loss: 2279403264.0, Continue Loss: 0.6725472211837769, Dynamic KL Loss: 2.8904379485394043e+18, Representation loss : 2.8904379485394043e+18\n",
      "Total Loss of 111: 9.444695790426522e+16, Recon Loss: 4313481740288.0, Reward Loss: 508237248.0, Continue Loss: 0.718811571598053, Dynamic KL Loss: 4.722132511193301e+18, Representation loss : 4.722132511193301e+18\n",
      "Total Loss of 112: 7.24768686079245e+19, Recon Loss: 5483892089815040.0, Reward Loss: 2858589184.0, Continue Loss: 0.7856758236885071, Dynamic KL Loss: 3.623569238584537e+21, Representation loss : 3.623569238584537e+21\n",
      "Total Loss of 113: 4606525834264576.0, Recon Loss: 355548856320.0, Reward Loss: 444823456.0, Continue Loss: 0.6606758236885071, Dynamic KL Loss: 2.303084987374633e+17, Representation loss : 2.303084987374633e+17\n",
      "Total Loss of 114: 9.61912673371926e+19, Recon Loss: 4987225292931072.0, Reward Loss: 778449536.0, Continue Loss: 0.7738044261932373, Dynamic KL Loss: 4.809314103175567e+21, Representation loss : 4.809314103175567e+21\n",
      "Total Loss of 115: 1.027184915382272e+16, Recon Loss: 2128156426240.0, Reward Loss: 1233326208.0, Continue Loss: 0.7856758236885071, Dynamic KL Loss: 5.134860176641229e+17, Representation loss : 5.134860176641229e+17\n",
      "Total Loss of 116: 1.1855130908384297e+18, Recon Loss: 1168376864964608.0, Reward Loss: 211475488.0, Continue Loss: 0.7425544261932373, Dynamic KL Loss: 5.921723776401565e+19, Representation loss : 5.921723776401565e+19\n",
      "Total Loss of 117: 677963339137024.0, Recon Loss: 75670503424.0, Reward Loss: 15224188.0, Continue Loss: 0.781311571598053, Dynamic KL Loss: 3.3894382956445696e+16, Representation loss : 3.3894382956445696e+16\n",
      "Total Loss of 118: 3.427782475173069e+17, Recon Loss: 16550857801728.0, Reward Loss: 2454267136.0, Continue Loss: 0.8006901741027832, Dynamic KL Loss: 1.7138084443609629e+19, Representation loss : 1.7138084443609629e+19\n",
      "Total Loss of 119: 2.0601566549508096e+16, Recon Loss: 3255744069632.0, Reward Loss: 142227328.0, Continue Loss: 0.7425544261932373, Dynamic KL Loss: 1.0299155653947556e+18, Representation loss : 1.0299155653947556e+18\n",
      "Total Loss of 120: 1.49006942795622e+18, Recon Loss: 527711827132416.0, Reward Loss: 77377680.0, Continue Loss: 0.7662972211837769, Dynamic KL Loss: 7.447708256898856e+19, Representation loss : 7.447708256898856e+19\n",
      "Total Loss of 121: 1.3297373367238656e+16, Recon Loss: 2384195223552.0, Reward Loss: 103359128.0, Continue Loss: 0.7469186782836914, Dynamic KL Loss: 6.647494744295342e+17, Representation loss : 6.647494744295342e+17\n",
      "Total Loss of 122: 6.22546919620608e+17, Recon Loss: 345087737331712.0, Reward Loss: 154279424.0, Continue Loss: 0.812561571598053, Dynamic KL Loss: 3.1110092169689432e+19, Representation loss : 3.1110092169689432e+19\n",
      "Total Loss of 123: 5289640382693376.0, Recon Loss: 711307624448.0, Reward Loss: 1606276864.0, Continue Loss: 0.7544258236885071, Dynamic KL Loss: 2.6444637627482112e+17, Representation loss : 2.6444637627482112e+17\n",
      "Total Loss of 124: 4.945609898806215e+18, Recon Loss: 361556554547200.0, Reward Loss: 14866917376.0, Continue Loss: 0.7888187170028687, Dynamic KL Loss: 2.4726244975547567e+20, Representation loss : 2.4726244975547567e+20\n",
      "Total Loss of 125: 3.770341919876448e+18, Recon Loss: 3188371750912.0, Reward Loss: 416022272.0, Continue Loss: 0.7856758236885071, Dynamic KL Loss: 1.885169332661015e+20, Representation loss : 1.885169332661015e+20\n",
      "Total Loss of 126: 5.344525877143142e+16, Recon Loss: 5944241553408.0, Reward Loss: 377248704.0, Continue Loss: 0.8050544261932373, Dynamic KL Loss: 2.671965812734034e+18, Representation loss : 2.671965812734034e+18\n",
      "Total Loss of 127: 2.1097635272196096e+16, Recon Loss: 726433398784.0, Reward Loss: 216792528.0, Continue Loss: 0.750061571598053, Dynamic KL Loss: 1.0548453422871347e+18, Representation loss : 1.0548453422871347e+18\n",
      "Total Loss of 128: 9.280713080071782e+16, Recon Loss: 9077702787072.0, Reward Loss: 656920832.0, Continue Loss: 0.8050544261932373, Dynamic KL Loss: 4.639902785331003e+18, Representation loss : 4.639902785331003e+18\n",
      "Total Loss of 129: 7300511321554944.0, Recon Loss: 982655172608.0, Reward Loss: 218555232.0, Continue Loss: 0.8244329690933228, Dynamic KL Loss: 3.649764595691684e+17, Representation loss : 3.649764595691684e+17\n",
      "Total Loss of 130: 1.0015118127949414e+17, Recon Loss: 4705446002688.0, Reward Loss: 339082848.0, Continue Loss: 0.7738044261932373, Dynamic KL Loss: 5.00732383720584e+18, Representation loss : 5.00732383720584e+18\n",
      "Total Loss of 131: 2.470715370504192e+16, Recon Loss: 12157684023296.0, Reward Loss: 1127510528.0, Continue Loss: 0.7381901741027832, Dynamic KL Loss: 1.2347497712860529e+18, Representation loss : 1.2347497712860529e+18\n",
      "Total Loss of 132: 1305684956151808.0, Recon Loss: 54530076672.0, Reward Loss: 221426528.0, Continue Loss: 0.781311571598053, Dynamic KL Loss: 6.528151003437466e+16, Representation loss : 6.528151003437466e+16\n",
      "Total Loss of 133: 1.613896427476353e+18, Recon Loss: 451632789716992.0, Reward Loss: 593291776.0, Continue Loss: 0.8050544261932373, Dynamic KL Loss: 8.067224125327383e+19, Representation loss : 8.067224125327383e+19\n",
      "Total Loss of 134: 1.1407325386036478e+19, Recon Loss: 83869655105536.0, Reward Loss: 129603616.0, Continue Loss: 0.7619329690933228, Dynamic KL Loss: 5.703620339830337e+20, Representation loss : 5.703620339830337e+20\n",
      "Total Loss of 135: 3.4960528014091223e+18, Recon Loss: 90543992340480.0, Reward Loss: 124195344.0, Continue Loss: 0.812561571598053, Dynamic KL Loss: 1.747981067840148e+20, Representation loss : 1.747981067840148e+20\n",
      "Total Loss of 136: 9.145171643151155e+16, Recon Loss: 22392487280640.0, Reward Loss: 260511520.0, Continue Loss: 0.7544258236885071, Dynamic KL Loss: 4.571466157961249e+18, Representation loss : 4.571466157961249e+18\n",
      "Total Loss of 137: 2.117954717047849e+17, Recon Loss: 65142922412032.0, Reward Loss: 75409888.0, Continue Loss: 0.6919258236885071, Dynamic KL Loss: 1.058651686615751e+19, Representation loss : 1.058651686615751e+19\n",
      "Total Loss of 138: 2.311728780856525e+16, Recon Loss: 2493775609856.0, Reward Loss: 220180176.0, Continue Loss: 0.812561571598053, Dynamic KL Loss: 1.1557396903477903e+18, Representation loss : 1.1557396903477903e+18\n",
      "Total Loss of 139: 5.122959681257472e+16, Recon Loss: 1397126201344.0, Reward Loss: 627387520.0, Continue Loss: 0.7662972211837769, Dynamic KL Loss: 2.561409918561157e+18, Representation loss : 2.561409918561157e+18\n",
      "Total Loss of 140: 2.2018415237563154e+19, Recon Loss: 1.2465963261755392e+16, Reward Loss: 1161571200.0, Continue Loss: 0.7500615119934082, Dynamic KL Loss: 1.1002975059109762e+21, Representation loss : 1.1002975059109762e+21\n",
      "Total Loss of 141: 3.3293679381499085e+18, Recon Loss: 6145788962930688.0, Reward Loss: 1851469440.0, Continue Loss: 0.7544258236885071, Dynamic KL Loss: 1.6616109990020645e+20, Representation loss : 1.6616109990020645e+20\n",
      "Total Loss of 142: 3819168134594560.0, Recon Loss: 392701968384.0, Reward Loss: 672259456.0, Continue Loss: 0.8169258236885071, Dynamic KL Loss: 1.9093874973815603e+17, Representation loss : 1.9093874973815603e+17\n",
      "Total Loss of 143: 5.715949494940467e+16, Recon Loss: 2968926289920.0, Reward Loss: 820206336.0, Continue Loss: 0.7263187170028687, Dynamic KL Loss: 2.857826158781661e+18, Representation loss : 2.857826158781661e+18\n",
      "Total Loss of 144: 7.64492897698699e+19, Recon Loss: 2698758806568960.0, Reward Loss: 777574400.0, Continue Loss: 0.7900400757789612, Dynamic KL Loss: 3.822329697164023e+21, Representation loss : 3.822329697164023e+21\n",
      "Total Loss of 145: 1.4459825850951926e+18, Recon Loss: 19332117561344.0, Reward Loss: 477272992.0, Continue Loss: 0.7619329690933228, Dynamic KL Loss: 7.229816278403881e+19, Representation loss : 7.229816278403881e+19\n",
      "Total Loss of 146: 2.423915044614963e+16, Recon Loss: 4331759730688.0, Reward Loss: 225337376.0, Continue Loss: 0.7544257640838623, Dynamic KL Loss: 1.211740978646352e+18, Representation loss : 1.211740978646352e+18\n",
      "Total Loss of 147: 4.092990016454656e+16, Recon Loss: 11574057107456.0, Reward Loss: 189042640.0, Continue Loss: 0.7781686782836914, Dynamic KL Loss: 2.045916261384192e+18, Representation loss : 2.045916261384192e+18\n",
      "Total Loss of 148: 5.631082281201304e+18, Recon Loss: 129275638317056.0, Reward Loss: 433776224.0, Continue Loss: 0.7662972211837769, Dynamic KL Loss: 2.8154766762339153e+20, Representation loss : 2.8154766762339153e+20\n",
      "Total Loss of 149: 1788275266158592.0, Recon Loss: 116860706816.0, Reward Loss: 292208672.0, Continue Loss: 0.7350472211837769, Dynamic KL Loss: 8.94079047041024e+16, Representation loss : 8.94079047041024e+16\n",
      "Total Loss of 150: 1781911735238656.0, Recon Loss: 579908337664.0, Reward Loss: 61530048.0, Continue Loss: 0.8825687170028687, Dynamic KL Loss: 8.906659224302387e+16, Representation loss : 8.906659224302387e+16\n",
      "Total Loss of 151: 6.926968781642138e+16, Recon Loss: 148213130592256.0, Reward Loss: 130069832.0, Continue Loss: 0.7738044261932373, Dynamic KL Loss: 3.456073733989466e+18, Representation loss : 3.456073733989466e+18\n",
      "Total Loss of 152: 2.606129461644493e+16, Recon Loss: 2279108247552.0, Reward Loss: 242230928.0, Continue Loss: 0.843811571598053, Dynamic KL Loss: 1.3029508282895565e+18, Representation loss : 1.3029508282895565e+18\n",
      "Total Loss of 153: 2.3396147287631593e+19, Recon Loss: 2657962254401536.0, Reward Loss: 296845824.0, Continue Loss: 0.8169258236885071, Dynamic KL Loss: 1.1696744730082002e+21, Representation loss : 1.1696744730082002e+21\n",
      "Total Loss of 154: 5.344928745075507e+16, Recon Loss: 9931679858688.0, Reward Loss: 26154898.0, Continue Loss: 0.7781686782836914, Dynamic KL Loss: 2.6719680117572895e+18, Representation loss : 2.6719680117572895e+18\n",
      "Total Loss of 155: 1.0202749572481024e+16, Recon Loss: 2357801254912.0, Reward Loss: 390721344.0, Continue Loss: 0.7856758236885071, Dynamic KL Loss: 5.100196010991288e+17, Representation loss : 5.100196010991288e+17\n",
      "Total Loss of 156: 4.646971545585975e+18, Recon Loss: 1079922617483264.0, Reward Loss: 419680576.0, Continue Loss: 0.812561571598053, Dynamic KL Loss: 2.3229457806423543e+20, Representation loss : 2.3229457806423543e+20\n",
      "Total Loss of 157: 3291585894678528.0, Recon Loss: 716003147776.0, Reward Loss: 195433904.0, Continue Loss: 0.8319401741027832, Dynamic KL Loss: 1.6454349564464333e+17, Representation loss : 1.6454349564464333e+17\n",
      "Total Loss of 158: 3.0390221016263557e+18, Recon Loss: 681216843972608.0, Reward Loss: 631740032.0, Continue Loss: 0.7231758236885071, Dynamic KL Loss: 1.5191704111157766e+20, Representation loss : 1.5191704111157766e+20\n",
      "Total Loss of 159: 5.820676568736858e+18, Recon Loss: 2869168613359616.0, Reward Loss: 519425184.0, Continue Loss: 0.8006901144981384, Dynamic KL Loss: 2.9089038505037162e+20, Representation loss : 2.9089038505037162e+20\n",
      "Total Loss of 160: 1.4347589078378086e+18, Recon Loss: 307025737154560.0, Reward Loss: 261450704.0, Continue Loss: 0.7156686782836914, Dynamic KL Loss: 7.1722594835177144e+19, Representation loss : 7.1722594835177144e+19\n",
      "Total Loss of 161: 2824976621109248.0, Recon Loss: 2703297347584.0, Reward Loss: 1624062464.0, Continue Loss: 0.812561571598053, Dynamic KL Loss: 1.4111359005150413e+17, Representation loss : 1.4111359005150413e+17\n",
      "Total Loss of 162: 7593803900780544.0, Recon Loss: 1004930727936.0, Reward Loss: 420261760.0, Continue Loss: 0.7856758236885071, Dynamic KL Loss: 3.796399245943112e+17, Representation loss : 3.796399245943112e+17\n",
      "Total Loss of 163: 5.271286892220908e+18, Recon Loss: 429848614928384.0, Reward Loss: 35114172.0, Continue Loss: 0.8944401741027832, Dynamic KL Loss: 2.6354285685530375e+20, Representation loss : 2.6354285685530375e+20\n",
      "Total Loss of 164: 4.516112756889354e+17, Recon Loss: 258477071007744.0, Reward Loss: 172377968.0, Continue Loss: 0.7156686782836914, Dynamic KL Loss: 2.2567641086846566e+19, Representation loss : 2.2567641086846566e+19\n",
      "Total Loss of 165: 1.3564481162948116e+18, Recon Loss: 164652587679744.0, Reward Loss: 13635250176.0, Continue Loss: 0.8631901741027832, Dynamic KL Loss: 6.781417404606133e+19, Representation loss : 6.781417404606133e+19\n",
      "Total Loss of 166: 2.7135224044616417e+18, Recon Loss: 244130621947904.0, Reward Loss: 340991168.0, Continue Loss: 0.8050543665885925, Dynamic KL Loss: 1.3566391949230447e+20, Representation loss : 1.3566391949230447e+20\n",
      "Total Loss of 167: 1.4888699982092698e+17, Recon Loss: 30487343005696.0, Reward Loss: 567725632.0, Continue Loss: 0.7619329690933228, Dynamic KL Loss: 7.442825105857577e+18, Representation loss : 7.442825105857577e+18\n",
      "Total Loss of 168: 1.5786684597514797e+19, Recon Loss: 2224281689784320.0, Reward Loss: 672129792.0, Continue Loss: 0.7662972211837769, Dynamic KL Loss: 7.892230428618926e+20, Representation loss : 7.892230428618926e+20\n",
      "Total Loss of 169: 1.5184165385273344e+16, Recon Loss: 2279079149568.0, Reward Loss: 865181760.0, Continue Loss: 0.7662972211837769, Dynamic KL Loss: 7.590943066014351e+17, Representation loss : 7.590943066014351e+17\n",
      "Total Loss of 170: 5.70369552374825e+16, Recon Loss: 1374768070656.0, Reward Loss: 226010144.0, Continue Loss: 0.7738043665885925, Dynamic KL Loss: 2.8517791197068e+18, Representation loss : 2.8517791197068e+18\n",
      "Total Loss of 171: 6384633168003072.0, Recon Loss: 903735017472.0, Reward Loss: 727050560.0, Continue Loss: 0.8244329690933228, Dynamic KL Loss: 3.1918643883697766e+17, Representation loss : 3.1918643883697766e+17\n",
      "Total Loss of 172: 2.439187948319539e+16, Recon Loss: 23144096071680.0, Reward Loss: 404281152.0, Continue Loss: 0.7306829690933228, Dynamic KL Loss: 1.2184367295816008e+18, Representation loss : 1.2184367295816008e+18\n",
      "Total Loss of 173: 6938205060333568.0, Recon Loss: 390924992512.0, Reward Loss: 1888493824.0, Continue Loss: 0.7931829690933228, Dynamic KL Loss: 3.468906271636193e+17, Representation loss : 3.468906271636193e+17\n",
      "Total Loss of 174: 4.024187928599698e+19, Recon Loss: 2591106256601088.0, Reward Loss: 670766208.0, Continue Loss: 0.7350472211837769, Dynamic KL Loss: 2.0119645561793062e+21, Representation loss : 2.0119645561793062e+21\n",
      "Total Loss of 175: 2.6939288323767665e+19, Recon Loss: 3918095995371520.0, Reward Loss: 752430080.0, Continue Loss: 0.7425544261932373, Dynamic KL Loss: 1.3467685359928717e+21, Representation loss : 1.3467685359928717e+21\n",
      "Total Loss of 176: 1.3096083711957402e+17, Recon Loss: 30440574418944.0, Reward Loss: 1481702656.0, Continue Loss: 0.6488043665885925, Dynamic KL Loss: 6.546519719568998e+18, Representation loss : 6.546519719568998e+18\n",
      "Total Loss of 177: 2.8068240474888995e+19, Recon Loss: 5232346592706560.0, Reward Loss: 492671232.0, Continue Loss: 0.7931829690933228, Dynamic KL Loss: 1.4031505071028065e+21, Representation loss : 1.4031505071028065e+21\n",
      "Total Loss of 178: 4814002282561536.0, Recon Loss: 2387596017664.0, Reward Loss: 92753120.0, Continue Loss: 0.6725472211837769, Dynamic KL Loss: 2.405807548394373e+17, Representation loss : 2.405807548394373e+17\n",
      "Total Loss of 179: 3.3349196472364564e+18, Recon Loss: 109352258109440.0, Reward Loss: 280070880.0, Continue Loss: 0.7888187170028687, Dynamic KL Loss: 1.6674051613976533e+20, Representation loss : 1.6674051613976533e+20\n",
      "Total Loss of 180: 6.209792909173064e+17, Recon Loss: 277948238135296.0, Reward Loss: 233236064.0, Continue Loss: 0.8050544261932373, Dynamic KL Loss: 3.103507029230302e+19, Representation loss : 3.103507029230302e+19\n",
      "Total Loss of 181: 6.1563071660399e+17, Recon Loss: 38454188572672.0, Reward Loss: 171893920.0, Continue Loss: 0.7425544261932373, Dynamic KL Loss: 3.0779614158752055e+19, Representation loss : 3.0779614158752055e+19\n",
      "Total Loss of 182: 1.5776276019150848e+16, Recon Loss: 130092302336.0, Reward Loss: 8826510.0, Continue Loss: 0.7662972211837769, Dynamic KL Loss: 7.888073026720236e+17, Representation loss : 7.888073026720236e+17\n",
      "Total Loss of 183: 2.23268274245206e+17, Recon Loss: 24988184739840.0, Reward Loss: 148168960.0, Continue Loss: 0.7781686782836914, Dynamic KL Loss: 1.1162165079368008e+19, Representation loss : 1.1162165079368008e+19\n",
      "Total Loss of 184: 4881689893404672.0, Recon Loss: 341600141312.0, Reward Loss: 2876583424.0, Continue Loss: 0.7694401741027832, Dynamic KL Loss: 2.4406728903124582e+17, Representation loss : 2.4406728903124582e+17\n",
      "Total Loss of 185: 2.226559579376845e+16, Recon Loss: 3882150002688.0, Reward Loss: 74788200.0, Continue Loss: 0.8157044649124146, Dynamic KL Loss: 1.1130856485767086e+18, Representation loss : 1.1130856485767086e+18\n",
      "Total Loss of 186: 9832096042319872.0, Recon Loss: 897196949504.0, Reward Loss: 1365108224.0, Continue Loss: 0.7156686782836914, Dynamic KL Loss: 4.915599003803976e+17, Representation loss : 4.915599003803976e+17\n",
      "Total Loss of 187: 5.3773032327361855e+19, Recon Loss: 2.8580479766626304e+16, Reward Loss: 1440487168.0, Continue Loss: 0.8244329690933228, Dynamic KL Loss: 2.687222743833193e+21, Representation loss : 2.687222743833193e+21\n",
      "Total Loss of 188: 1.7722079599342387e+17, Recon Loss: 3923328368640.0, Reward Loss: 688234240.0, Continue Loss: 0.8319401741027832, Dynamic KL Loss: 8.860843811723543e+18, Representation loss : 8.860843811723543e+18\n",
      "Total Loss of 189: 1.3068929210725171e+17, Recon Loss: 8266480877568.0, Reward Loss: 113894192.0, Continue Loss: 0.8244329690933228, Dynamic KL Loss: 6.534051257710019e+18, Representation loss : 6.534051257710019e+18\n",
      "Total Loss of 190: 1.7974156383905382e+17, Recon Loss: 34472298807296.0, Reward Loss: 2761202176.0, Continue Loss: 0.7231758236885071, Dynamic KL Loss: 8.985354157720338e+18, Representation loss : 8.985354157720338e+18\n",
      "Total Loss of 191: 1016101014077440.0, Recon Loss: 198743375872.0, Reward Loss: 437227872.0, Continue Loss: 0.781311571598053, Dynamic KL Loss: 5.079509215110758e+16, Representation loss : 5.079509215110758e+16\n",
      "Total Loss of 192: 3.9746802460236186e+17, Recon Loss: 41801599680512.0, Reward Loss: 104962608.0, Continue Loss: 0.7856758236885071, Dynamic KL Loss: 1.9871310921074737e+19, Representation loss : 1.9871310921074737e+19\n",
      "Total Loss of 193: 1.2390307472965894e+19, Recon Loss: 998385079287808.0, Reward Loss: 190862880.0, Continue Loss: 0.7425544261932373, Dynamic KL Loss: 6.19465484407696e+20, Representation loss : 6.19465484407696e+20\n",
      "Total Loss of 194: 1.2508008543451873e+18, Recon Loss: 10083359522816.0, Reward Loss: 2761342208.0, Continue Loss: 0.7037972211837769, Dynamic KL Loss: 6.253953969068966e+19, Representation loss : 6.253953969068966e+19\n",
      "Total Loss of 195: 2.2505893201025434e+17, Recon Loss: 78243658989568.0, Reward Loss: 107284952.0, Continue Loss: 0.7900400757789612, Dynamic KL Loss: 1.1249035294055334e+19, Representation loss : 1.1249035294055334e+19\n",
      "Total Loss of 196: 1.8787673011388416e+16, Recon Loss: 3172661723136.0, Reward Loss: 15646646.0, Continue Loss: 0.8287972211837769, Dynamic KL Loss: 9.392250288372449e+17, Representation loss : 9.392250288372449e+17\n",
      "Total Loss of 197: 6.895292109343949e+16, Recon Loss: 2121357066240.0, Reward Loss: 493781024.0, Continue Loss: 0.8394473195075989, Dynamic KL Loss: 3.4475401493683896e+18, Representation loss : 3.4475401493683896e+18\n",
      "Total Loss of 198: 2.4799295648487703e+19, Recon Loss: 1087298686943232.0, Reward Loss: 1244952960.0, Continue Loss: 0.8319401741027832, Dynamic KL Loss: 1.239910501734345e+21, Representation loss : 1.239910501734345e+21\n",
      "Total Loss of 199: 2133217377255424.0, Recon Loss: 410638974976.0, Reward Loss: 269066240.0, Continue Loss: 0.7662972211837769, Dynamic KL Loss: 1.0664032710793626e+17, Representation loss : 1.0664032710793626e+17\n",
      "Total Loss of 200: 8.353639235269427e+17, Recon Loss: 9269894184960.0, Reward Loss: 16654680064.0, Continue Loss: 0.7694401741027832, Dynamic KL Loss: 4.176773314451289e+19, Representation loss : 4.176773314451289e+19\n",
      "Total Loss of 201: 4937777871323136.0, Recon Loss: 493465337856.0, Reward Loss: 126146416.0, Continue Loss: 0.7813115119934082, Dynamic KL Loss: 2.468642060941394e+17, Representation loss : 2.468642060941394e+17\n",
      "Total Loss of 202: 4.409985145797345e+17, Recon Loss: 352576482574336.0, Reward Loss: 1728268800.0, Continue Loss: 0.781311571598053, Dynamic KL Loss: 2.2032297671375454e+19, Representation loss : 2.2032297671375454e+19\n",
      "Total Loss of 203: 1.3640853927808205e+17, Recon Loss: 25861124259840.0, Reward Loss: 138339760.0, Continue Loss: 0.7619329690933228, Dynamic KL Loss: 6.819133732071408e+18, Representation loss : 6.819133732071408e+18\n",
      "Total Loss of 204: 1.1567049241180242e+18, Recon Loss: 233834813587456.0, Reward Loss: 180000992.0, Continue Loss: 0.750061571598053, Dynamic KL Loss: 5.782354960120493e+19, Representation loss : 5.782354960120493e+19\n",
      "Total Loss of 205: 5.51248272073687e+16, Recon Loss: 12102274121728.0, Reward Loss: 97724816.0, Continue Loss: 0.7738043665885925, Dynamic KL Loss: 2.755636173706625e+18, Representation loss : 2.755636173706625e+18\n",
      "Total Loss of 206: 5.389921667981194e+19, Recon Loss: 8327359627264.0, Reward Loss: 2752169216.0, Continue Loss: 0.7113044261932373, Dynamic KL Loss: 2.694960490942969e+21, Representation loss : 2.694960490942969e+21\n",
      "Total Loss of 207: 864844546834432.0, Recon Loss: 127886917632.0, Reward Loss: 50102836.0, Continue Loss: 0.7662972211837769, Dynamic KL Loss: 4.32358294510633e+16, Representation loss : 4.32358294510633e+16\n",
      "Total Loss of 208: 2.312916992148898e+18, Recon Loss: 86905551060992.0, Reward Loss: 308840576.0, Continue Loss: 0.7738044261932373, Dynamic KL Loss: 1.1564150488724773e+20, Representation loss : 1.1564150488724773e+20\n",
      "Total Loss of 209: 5.371559689794355e+16, Recon Loss: 12108151390208.0, Reward Loss: 145531584.0, Continue Loss: 0.7037972211837769, Dynamic KL Loss: 2.685174520796414e+18, Representation loss : 2.685174520796414e+18\n",
      "Total Loss of 210: 2164639760646144.0, Recon Loss: 609211973632.0, Reward Loss: 119989488.0, Continue Loss: 0.7888187170028687, Dynamic KL Loss: 1.0820152195022848e+17, Representation loss : 1.0820152195022848e+17\n",
      "Total Loss of 211: 1.6200288505010586e+17, Recon Loss: 684141248512.0, Reward Loss: 10454020.0, Continue Loss: 0.7619329690933228, Dynamic KL Loss: 8.100110408163e+18, Representation loss : 8.100110408163e+18\n",
      "Total Loss of 212: 2.4467116143306342e+17, Recon Loss: 124832461094912.0, Reward Loss: 4645371904.0, Continue Loss: 0.8363044261932373, Dynamic KL Loss: 1.2227316968776008e+19, Representation loss : 1.2227316968776008e+19\n",
      "Total Loss of 213: 8.164115728794911e+17, Recon Loss: 72908957286400.0, Reward Loss: 285524352.0, Continue Loss: 0.7113044261932373, Dynamic KL Loss: 4.081693266341685e+19, Representation loss : 4.081693266341685e+19\n",
      "Total Loss of 214: 9.497826631822082e+18, Recon Loss: 1111727924051968.0, Reward Loss: 575519872.0, Continue Loss: 0.781311571598053, Dynamic KL Loss: 4.7483576007441305e+20, Representation loss : 4.7483576007441305e+20\n",
      "Total Loss of 215: 5.020670740135936e+16, Recon Loss: 1135760900096.0, Reward Loss: 106556240.0, Continue Loss: 0.843811571598053, Dynamic KL Loss: 2.510278504700969e+18, Representation loss : 2.510278504700969e+18\n",
      "Total Loss of 216: 1.2500259735255122e+19, Recon Loss: 727446663987200.0, Reward Loss: 210627600.0, Continue Loss: 0.7619329690933228, Dynamic KL Loss: 6.249766237142023e+20, Representation loss : 6.249766237142023e+20\n",
      "Total Loss of 217: 6.106601378956286e+19, Recon Loss: 5052228549214208.0, Reward Loss: 129300936.0, Continue Loss: 0.7931829690933228, Dynamic KL Loss: 3.0530481712396616e+21, Representation loss : 3.0530481712396616e+21\n",
      "Total Loss of 218: 8996714165829632.0, Recon Loss: 562355109888.0, Reward Loss: 226245152.0, Continue Loss: 0.8050544261932373, Dynamic KL Loss: 4.498075955830456e+17, Representation loss : 4.498075955830456e+17\n",
      "Total Loss of 219: 1.6013240617685484e+18, Recon Loss: 12418442854400.0, Reward Loss: 113174016.0, Continue Loss: 0.8556829690933228, Dynamic KL Loss: 8.006558351362517e+19, Representation loss : 8.006558351362517e+19\n",
      "Total Loss of 220: 1.9021737991602176e+16, Recon Loss: 1589534392320.0, Reward Loss: 67534128.0, Continue Loss: 0.8094186782836914, Dynamic KL Loss: 9.510074641599693e+17, Representation loss : 9.510074641599693e+17\n",
      "Total Loss of 221: 1.5858836749552714e+19, Recon Loss: 347900739584000.0, Reward Loss: 124565960.0, Continue Loss: 0.7900400757789612, Dynamic KL Loss: 7.929244388056378e+20, Representation loss : 7.929244388056378e+20\n",
      "Total Loss of 222: 1.0687887220289621e+20, Recon Loss: 1523388929540096.0, Reward Loss: 1121105536.0, Continue Loss: 0.7544258236885071, Dynamic KL Loss: 5.343867735046401e+21, Representation loss : 5.343867735046401e+21\n",
      "Total Loss of 223: 9.598488020856603e+18, Recon Loss: 449658245611520.0, Reward Loss: 308128512.0, Continue Loss: 0.7381901144981384, Dynamic KL Loss: 4.799019226271119e+20, Representation loss : 4.799019226271119e+20\n",
      "Total Loss of 224: 1.0749227682077082e+18, Recon Loss: 15339369791488.0, Reward Loss: 563261312.0, Continue Loss: 0.7350472211837769, Dynamic KL Loss: 5.374537301285352e+19, Representation loss : 5.374537301285352e+19\n",
      "Total Loss of 225: 1.5342602433855488e+17, Recon Loss: 77765986484224.0, Reward Loss: 119671600.0, Continue Loss: 0.6962900757789612, Dynamic KL Loss: 7.667413549970358e+18, Representation loss : 7.667413549970358e+18\n",
      "Total Loss of 226: 2.401381773574406e+18, Recon Loss: 5333520482304.0, Reward Loss: 127529504.0, Continue Loss: 0.6919258236885071, Dynamic KL Loss: 1.2006881599983662e+20, Representation loss : 1.2006881599983662e+20\n",
      "Total Loss of 227: 4.990840474278298e+16, Recon Loss: 3439331377152.0, Reward Loss: 44234816.0, Continue Loss: 0.7781686782836914, Dynamic KL Loss: 2.495248180749271e+18, Representation loss : 2.495248180749271e+18\n",
      "Total Loss of 228: 4967647221383168.0, Recon Loss: 150165307392.0, Reward Loss: 134778080.0, Continue Loss: 0.7069401741027832, Dynamic KL Loss: 2.483748491713577e+17, Representation loss : 2.483748491713577e+17\n",
      "Total Loss of 229: 5.981159416757276e+19, Recon Loss: 1.567142835126272e+16, Reward Loss: 1273119616.0, Continue Loss: 0.8169258236885071, Dynamic KL Loss: 2.989795958898173e+21, Representation loss : 2.989795958898173e+21\n",
      "Total Loss of 230: 823547630977024.0, Recon Loss: 74236477440.0, Reward Loss: 416681920.0, Continue Loss: 0.7469186782836914, Dynamic KL Loss: 4.117365244349645e+16, Representation loss : 4.117365244349645e+16\n",
      "Total Loss of 231: 2.499671181020365e+16, Recon Loss: 6808741085184.0, Reward Loss: 1300317952.0, Continue Loss: 0.7156686782836914, Dynamic KL Loss: 1.2494951842872033e+18, Representation loss : 1.2494951842872033e+18\n",
      "Total Loss of 232: 4.885811309662175e+18, Recon Loss: 190140903325696.0, Reward Loss: 226431984.0, Continue Loss: 0.8319401741027832, Dynamic KL Loss: 2.4428104920997036e+20, Representation loss : 2.4428104920997036e+20\n",
      "Total Loss of 233: 3.694403307490509e+16, Recon Loss: 2122492936192.0, Reward Loss: 176405888.0, Continue Loss: 0.7662972211837769, Dynamic KL Loss: 1.847095696902062e+18, Representation loss : 1.847095696902062e+18\n",
      "Total Loss of 234: 7.308090950989906e+17, Recon Loss: 60010155474944.0, Reward Loss: 723788672.0, Continue Loss: 0.750061571598053, Dynamic KL Loss: 3.65374530882057e+19, Representation loss : 3.65374530882057e+19\n",
      "Total Loss of 235: 5.504127061148985e+19, Recon Loss: 3006896671817728.0, Reward Loss: 1051903616.0, Continue Loss: 0.7975472211837769, Dynamic KL Loss: 2.751913293305673e+21, Representation loss : 2.751913293305673e+21\n",
      "Total Loss of 236: 2295026780471296.0, Recon Loss: 493699760128.0, Reward Loss: 269687712.0, Continue Loss: 0.7888187170028687, Dynamic KL Loss: 1.1472665101467648e+17, Representation loss : 1.1472665101467648e+17\n",
      "Total Loss of 237: 7010252062982144.0, Recon Loss: 1324217401344.0, Reward Loss: 2097393536.0, Continue Loss: 0.781311571598053, Dynamic KL Loss: 3.504462759691551e+17, Representation loss : 3.504462759691551e+17\n",
      "Total Loss of 238: 2045147596455936.0, Recon Loss: 321295024128.0, Reward Loss: 572651904.0, Continue Loss: 0.7662972211837769, Dynamic KL Loss: 1.0224129275435418e+17, Representation loss : 1.0224129275435418e+17\n",
      "Total Loss of 239: 7.18756523513217e+17, Recon Loss: 2565378670592.0, Reward Loss: 1644909568.0, Continue Loss: 0.8556829690933228, Dynamic KL Loss: 3.593769588353296e+19, Representation loss : 3.593769588353296e+19\n",
      "Total Loss of 240: 3.128377542445944e+19, Recon Loss: 940288533069824.0, Reward Loss: 2032359296.0, Continue Loss: 0.7231758236885071, Dynamic KL Loss: 1.5641418088823264e+21, Representation loss : 1.5641418088823264e+21\n",
      "Total Loss of 241: 1.3037538840946934e+18, Recon Loss: 23483169898496.0, Reward Loss: 1379130752.0, Continue Loss: 0.7006543278694153, Dynamic KL Loss: 6.5186521575583646e+19, Representation loss : 6.5186521575583646e+19\n",
      "Total Loss of 242: 7.817578525900145e+17, Recon Loss: 57868925534208.0, Reward Loss: 350222080.0, Continue Loss: 0.8319401741027832, Dynamic KL Loss: 3.908499953953014e+19, Representation loss : 3.908499953953014e+19\n",
      "Total Loss of 243: 4162694382878720.0, Recon Loss: 549031182336.0, Reward Loss: 142840864.0, Continue Loss: 0.7931829690933228, Dynamic KL Loss: 2.081072630286254e+17, Representation loss : 2.081072630286254e+17\n",
      "Total Loss of 244: 3920493392429056.0, Recon Loss: 842874814464.0, Reward Loss: 474836864.0, Continue Loss: 0.8750615119934082, Dynamic KL Loss: 1.9598251881240986e+17, Representation loss : 1.9598251881240986e+17\n",
      "Total Loss of 245: 1547877625102336.0, Recon Loss: 275601293312.0, Reward Loss: 214181872.0, Continue Loss: 0.750061571598053, Dynamic KL Loss: 7.738008930982298e+16, Representation loss : 7.738008930982298e+16\n",
      "Total Loss of 246: 6186276545888256.0, Recon Loss: 743267172352.0, Reward Loss: 168025808.0, Continue Loss: 0.7888187170028687, Dynamic KL Loss: 3.092766436150477e+17, Representation loss : 3.092766436150477e+17\n",
      "Total Loss of 247: 2.5733299989957837e+18, Recon Loss: 171107729408.0, Reward Loss: 623860672.0, Continue Loss: 0.7662972211837769, Dynamic KL Loss: 1.2866649555174267e+20, Representation loss : 1.2866649555174267e+20\n",
      "Total Loss of 248: 1.4250493955308257e+18, Recon Loss: 105116405334016.0, Reward Loss: 259167680.0, Continue Loss: 0.7156686782836914, Dynamic KL Loss: 7.124721438583842e+19, Representation loss : 7.124721438583842e+19\n",
      "Total Loss of 249: 9.138443559702102e+18, Recon Loss: 8334124729237504.0, Reward Loss: 78975368.0, Continue Loss: 0.7350472211837769, Dynamic KL Loss: 4.565054762723175e+20, Representation loss : 4.565054762723175e+20\n",
      "Total Loss of 250: 5.312103072818371e+19, Recon Loss: 23520855719936.0, Reward Loss: 294344032.0, Continue Loss: 0.7738044261932373, Dynamic KL Loss: 2.656050516062395e+21, Representation loss : 2.656050516062395e+21\n",
      "Total Loss of 251: 3521204241563648.0, Recon Loss: 762633912320.0, Reward Loss: 23513016320.0, Continue Loss: 0.8319401741027832, Dynamic KL Loss: 1.7602090239000576e+17, Representation loss : 1.7602090239000576e+17\n",
      "Total Loss of 252: 1.0897259055693169e+18, Recon Loss: 88034087272448.0, Reward Loss: 490866656.0, Continue Loss: 0.7156686782836914, Dynamic KL Loss: 5.4481896269882065e+19, Representation loss : 5.4481896269882065e+19\n",
      "Total Loss of 253: 2.672756859810611e+16, Recon Loss: 10358458679296.0, Reward Loss: 70293528.0, Continue Loss: 0.7113044261932373, Dynamic KL Loss: 1.335860585698427e+18, Representation loss : 1.335860585698427e+18\n",
      "Total Loss of 254: 8.030908520700314e+17, Recon Loss: 411850017603584.0, Reward Loss: 233616096.0, Continue Loss: 0.7738044261932373, Dynamic KL Loss: 4.013395122461449e+19, Representation loss : 4.013395122461449e+19\n",
      "Total Loss of 255: 1.4273903975202816e+16, Recon Loss: 1129039265792.0, Reward Loss: 321534336.0, Continue Loss: 0.7662972211837769, Dynamic KL Loss: 7.136387092027802e+17, Representation loss : 7.136387092027802e+17\n",
      "Total Loss of 256: 6.133201616376955e+17, Recon Loss: 30026829398016.0, Reward Loss: 108055720.0, Continue Loss: 0.718811571598053, Dynamic KL Loss: 3.0664506286440186e+19, Representation loss : 3.0664506286440186e+19\n",
      "Total Loss of 257: 1.0000730331105198e+18, Recon Loss: 204458361356288.0, Reward Loss: 114197184.0, Continue Loss: 0.7587900757789612, Dynamic KL Loss: 4.999343032055628e+19, Representation loss : 4.999343032055628e+19\n",
      "Total Loss of 258: 1.3491331942842368e+16, Recon Loss: 792555814912.0, Reward Loss: 199725968.0, Continue Loss: 0.7350472211837769, Dynamic KL Loss: 6.74526950299009e+17, Representation loss : 6.74526950299009e+17\n",
      "Total Loss of 259: 3.461031157041201e+18, Recon Loss: 6496096616448.0, Reward Loss: 926581888.0, Continue Loss: 0.7306829690933228, Dynamic KL Loss: 1.7305123789417637e+20, Representation loss : 1.7305123789417637e+20\n",
      "Total Loss of 260: 1.6219993814964634e+17, Recon Loss: 7063996989440.0, Reward Loss: 341261792.0, Continue Loss: 0.7469186782836914, Dynamic KL Loss: 8.109643723731632e+18, Representation loss : 8.109643723731632e+18\n",
      "Total Loss of 261: 1.4517275333503222e+18, Recon Loss: 542094162657280.0, Reward Loss: 801923456.0, Continue Loss: 0.7156686782836914, Dynamic KL Loss: 7.255927040735655e+19, Representation loss : 7.255927040735655e+19\n",
      "Total Loss of 262: 2.307147768738611e+16, Recon Loss: 5577126707200.0, Reward Loss: 115961511936.0, Continue Loss: 0.8513187170028687, Dynamic KL Loss: 1.153289291246338e+18, Representation loss : 1.153289291246338e+18\n",
      "Total Loss of 263: 6.807882649486701e+19, Recon Loss: 7.645581234772378e+16, Reward Loss: 673645760.0, Continue Loss: 0.7738044261932373, Dynamic KL Loss: 3.4001186394729223e+21, Representation loss : 3.4001186394729223e+21\n",
      "Total Loss of 264: 2465065341026304.0, Recon Loss: 664724635648.0, Reward Loss: 1633225600.0, Continue Loss: 0.7738044261932373, Dynamic KL Loss: 1.2321994884251648e+17, Representation loss : 1.2321994884251648e+17\n",
      "Total Loss of 265: 2.754036109410304e+16, Recon Loss: 2066695323648.0, Reward Loss: 150343536.0, Continue Loss: 0.7931829690933228, Dynamic KL Loss: 1.3769148380510945e+18, Representation loss : 1.3769148380510945e+18\n",
      "Total Loss of 266: 4.046078665660826e+16, Recon Loss: 377438470144.0, Reward Loss: 178336704.0, Continue Loss: 0.6650400757789612, Dynamic KL Loss: 2.0230205810031985e+18, Representation loss : 2.0230205810031985e+18\n",
      "Total Loss of 267: 2.1156871461142528e+18, Recon Loss: 225095796654080.0, Reward Loss: 2271980800.0, Continue Loss: 0.8125615119934082, Dynamic KL Loss: 1.0577310655298142e+20, Representation loss : 1.0577310655298142e+20\n",
      "Total Loss of 268: 1.7661921280917504e+16, Recon Loss: 380301967360.0, Reward Loss: 139591168.0, Continue Loss: 0.6919258236885071, Dynamic KL Loss: 8.83077024455852e+17, Representation loss : 8.83077024455852e+17\n",
      "Total Loss of 269: 2.9395632484591337e+19, Recon Loss: 1.1460114133286912e+16, Reward Loss: 15529648128.0, Continue Loss: 0.7975472211837769, Dynamic KL Loss: 1.4692087434871235e+21, Representation loss : 1.4692087434871235e+21\n",
      "Total Loss of 270: 4036245982281728.0, Recon Loss: 1686138257408.0, Reward Loss: 238362240.0, Continue Loss: 0.7425544261932373, Dynamic KL Loss: 2.0172798246361498e+17, Representation loss : 2.0172798246361498e+17\n",
      "Total Loss of 271: 1281607369490432.0, Recon Loss: 65769758720.0, Reward Loss: 106900152.0, Continue Loss: 0.781311571598053, Dynamic KL Loss: 6.407707235555738e+16, Representation loss : 6.407707235555738e+16\n",
      "Total Loss of 272: 7114478034354176.0, Recon Loss: 194158280704.0, Reward Loss: 28339632.0, Continue Loss: 0.7069401741027832, Dynamic KL Loss: 3.557142079765217e+17, Representation loss : 3.557142079765217e+17\n",
      "Total Loss of 273: 1.015385566478336e+16, Recon Loss: 948657520640.0, Reward Loss: 339563392.0, Continue Loss: 0.750061571598053, Dynamic KL Loss: 5.0764530881816166e+17, Representation loss : 5.0764530881816166e+17\n",
      "Total Loss of 274: 1.6418174257520968e+18, Recon Loss: 630808444928.0, Reward Loss: 115405048.0, Continue Loss: 0.8169258236885071, Dynamic KL Loss: 8.209084874761647e+19, Representation loss : 8.209084874761647e+19\n",
      "Total Loss of 275: 1.0407806644225311e+18, Recon Loss: 234607672819712.0, Reward Loss: 999901184.0, Continue Loss: 0.8200687170028687, Dynamic KL Loss: 5.202730253156981e+19, Representation loss : 5.202730253156981e+19\n",
      "Total Loss of 276: 3.206293004583174e+18, Recon Loss: 496233642721280.0, Reward Loss: 216771136.0, Continue Loss: 0.7738044261932373, Dynamic KL Loss: 1.6028984854537096e+20, Representation loss : 1.6028984854537096e+20\n",
      "Total Loss of 277: 2.211443270179881e+17, Recon Loss: 25421611532288.0, Reward Loss: 138624976.0, Continue Loss: 0.7738044261932373, Dynamic KL Loss: 1.105594565905508e+19, Representation loss : 1.105594565905508e+19\n",
      "Total Loss of 278: 8.696574905364041e+19, Recon Loss: 1345126848790528.0, Reward Loss: 1995397632.0, Continue Loss: 0.7544258236885071, Dynamic KL Loss: 4.348220373676633e+21, Representation loss : 4.348220373676633e+21\n",
      "Total Loss of 279: 4965127149322240.0, Recon Loss: 802905653248.0, Reward Loss: 4237142272.0, Continue Loss: 0.781311571598053, Dynamic KL Loss: 2.4821600410088243e+17, Representation loss : 2.4821600410088243e+17\n",
      "Total Loss of 280: 1.2714059771276165e+18, Recon Loss: 518866912411648.0, Reward Loss: 83770600.0, Continue Loss: 0.7113044261932373, Dynamic KL Loss: 6.354435697903508e+19, Representation loss : 6.354435697903508e+19\n",
      "Total Loss of 281: 1.314043388785328e+18, Recon Loss: 4911928442880.0, Reward Loss: 285957824.0, Continue Loss: 0.7931829690933228, Dynamic KL Loss: 6.570192864621992e+19, Representation loss : 6.570192864621992e+19\n",
      "Total Loss of 282: 6548331014651904.0, Recon Loss: 282865401856.0, Reward Loss: 121056216.0, Continue Loss: 0.7200329303741455, Dynamic KL Loss: 3.2740240203658035e+17, Representation loss : 3.2740240203658035e+17\n",
      "Total Loss of 283: 1.2470982489386516e+18, Recon Loss: 14392911462400.0, Reward Loss: 294656224.0, Continue Loss: 0.8081973195075989, Dynamic KL Loss: 6.2354197214618714e+19, Representation loss : 6.2354197214618714e+19\n",
      "Total Loss of 284: 1.568092010013786e+18, Recon Loss: 29427507396608.0, Reward Loss: 312281984.0, Continue Loss: 0.7738044261932373, Dynamic KL Loss: 7.840313072852088e+19, Representation loss : 7.840313072852088e+19\n",
      "Total Loss of 285: 2172097031831552.0, Recon Loss: 19694223360.0, Reward Loss: 97401688.0, Continue Loss: 0.8050544261932373, Dynamic KL Loss: 1.0860386589658317e+17, Representation loss : 1.0860386589658317e+17\n",
      "Total Loss of 286: 6.462367909942395e+17, Recon Loss: 890451918848.0, Reward Loss: 326490464.0, Continue Loss: 0.7544258236885071, Dynamic KL Loss: 3.231179460717419e+19, Representation loss : 3.231179460717419e+19\n",
      "Total Loss of 287: 5.448724429443957e+18, Recon Loss: 477629958324224.0, Reward Loss: 34167488.0, Continue Loss: 0.7619329690933228, Dynamic KL Loss: 2.7241234447768905e+20, Representation loss : 2.7241234447768905e+20\n",
      "Total Loss of 288: 9.86581338242941e+18, Recon Loss: 83808862863360.0, Reward Loss: 683991936.0, Continue Loss: 0.7575687170028687, Dynamic KL Loss: 4.9328647998216864e+20, Representation loss : 4.9328647998216864e+20\n",
      "Total Loss of 289: 6.959722202241434e+16, Recon Loss: 17297525702656.0, Reward Loss: 1137813120.0, Continue Loss: 0.7037972211837769, Dynamic KL Loss: 3.47899635240534e+18, Representation loss : 3.47899635240534e+18\n",
      "Total Loss of 290: 6.165777534567842e+18, Recon Loss: 140855868391424.0, Reward Loss: 229404368.0, Continue Loss: 0.6800543665885925, Dynamic KL Loss: 3.0828184425202083e+20, Representation loss : 3.0828184425202083e+20\n",
      "Total Loss of 291: 7.043528181101363e+16, Recon Loss: 141116686336.0, Reward Loss: 2383598848.0, Continue Loss: 0.781311571598053, Dynamic KL Loss: 3.5217569093653627e+18, Representation loss : 3.5217569093653627e+18\n",
      "Total Loss of 292: 4793014924869632.0, Recon Loss: 171250057216.0, Reward Loss: 160285008.0, Continue Loss: 0.7144473195075989, Dynamic KL Loss: 2.3964214986643866e+17, Representation loss : 2.3964214986643866e+17\n",
      "Total Loss of 293: 1.9098542744272896e+16, Recon Loss: 45253324800.0, Reward Loss: 46836584.0, Continue Loss: 0.7856758236885071, Dynamic KL Loss: 9.549248866507817e+17, Representation loss : 9.549248866507817e+17\n",
      "Total Loss of 294: 8.390191262384259e+18, Recon Loss: 77089889845248.0, Reward Loss: 189101920.0, Continue Loss: 0.6844186782836914, Dynamic KL Loss: 4.1950573132119015e+20, Representation loss : 4.1950573132119015e+20\n",
      "Total Loss of 295: 6.77690698800667e+18, Recon Loss: 415924901380096.0, Reward Loss: 579296256.0, Continue Loss: 0.7425544261932373, Dynamic KL Loss: 3.3882455323740576e+20, Representation loss : 3.3882455323740576e+20\n",
      "Total Loss of 296: 1.7466599053197312e+16, Recon Loss: 1077123088384.0, Reward Loss: 401251072.0, Continue Loss: 0.7856758236885071, Dynamic KL Loss: 8.732761152448102e+17, Representation loss : 8.732761152448102e+17\n",
      "Total Loss of 297: 1.640371952790641e+19, Recon Loss: 56002611249152.0, Reward Loss: 90581616.0, Continue Loss: 0.8050544261932373, Dynamic KL Loss: 8.201831792377395e+20, Representation loss : 8.201831792377395e+20\n",
      "Total Loss of 298: 5665087633227776.0, Recon Loss: 519815987200.0, Reward Loss: 1732890752.0, Continue Loss: 0.6650400757789612, Dynamic KL Loss: 2.832282854400983e+17, Representation loss : 2.832282854400983e+17\n",
      "Total Loss of 299: 2.124293628356251e+19, Recon Loss: 978882370994176.0, Reward Loss: 1074812288.0, Continue Loss: 0.6725472211837769, Dynamic KL Loss: 1.0620979035028754e+21, Representation loss : 1.0620979035028754e+21\n",
      "Total Loss of 300: 1.6641669237319926e+18, Recon Loss: 16435497664512.0, Reward Loss: 63403928.0, Continue Loss: 0.7113044261932373, Dynamic KL Loss: 8.320753034897182e+19, Representation loss : 8.320753034897182e+19\n",
      "Total Loss of 301: 3.4164943390465065e+18, Recon Loss: 948633050546176.0, Reward Loss: 346002624.0, Continue Loss: 0.7662972211837769, Dynamic KL Loss: 1.707772895182612e+20, Representation loss : 1.707772895182612e+20\n",
      "Total Loss of 302: 2399544004313088.0, Recon Loss: 141314998272.0, Reward Loss: 329907200.0, Continue Loss: 0.7113044261932373, Dynamic KL Loss: 1.1997011029839053e+17, Representation loss : 1.1997011029839053e+17\n",
      "Total Loss of 303: 7.974168223148933e+17, Recon Loss: 10652711124992.0, Reward Loss: 383122432.0, Continue Loss: 0.8319401741027832, Dynamic KL Loss: 3.987031032650636e+19, Representation loss : 3.987031032650636e+19\n",
      "Total Loss of 304: 4614377571352576.0, Recon Loss: 412746252288.0, Reward Loss: 431305760.0, Continue Loss: 0.8050544261932373, Dynamic KL Loss: 2.3069820689003315e+17, Representation loss : 2.3069820689003315e+17\n",
      "Total Loss of 305: 2.143844736958464e+16, Recon Loss: 3180318687232.0, Reward Loss: 4185259008.0, Continue Loss: 0.7662972211837769, Dynamic KL Loss: 1.0717631841063404e+18, Representation loss : 1.0717631841063404e+18\n",
      "Total Loss of 306: 2725453102055424.0, Recon Loss: 177106681856.0, Reward Loss: 208579584.0, Continue Loss: 0.7231758236885071, Dynamic KL Loss: 1.3626379888020685e+17, Representation loss : 1.3626379888020685e+17\n",
      "Total Loss of 307: 7.972826131768279e+17, Recon Loss: 342698728882176.0, Reward Loss: 125653056.0, Continue Loss: 0.750061571598053, Dynamic KL Loss: 3.9846996281950994e+19, Representation loss : 3.9846996281950994e+19\n",
      "Total Loss of 308: 9.420108477046456e+17, Recon Loss: 259518835458048.0, Reward Loss: 102734744.0, Continue Loss: 0.7113044261932373, Dynamic KL Loss: 4.708756622387918e+19, Representation loss : 4.708756622387918e+19\n",
      "Total Loss of 309: 1707054481801216.0, Recon Loss: 144772431872.0, Reward Loss: 1126119168.0, Continue Loss: 0.750061571598053, Dynamic KL Loss: 8.534543257776947e+16, Representation loss : 8.534543257776947e+16\n",
      "Total Loss of 310: 3.702022321775575e+17, Recon Loss: 28867142090752.0, Reward Loss: 166970336.0, Continue Loss: 0.7350472211837769, Dynamic KL Loss: 1.8508668568585896e+19, Representation loss : 1.8508668568585896e+19\n",
      "Total Loss of 311: 2.838473929499083e+18, Recon Loss: 7780541399040.0, Reward Loss: 795461760.0, Continue Loss: 0.7587900757789612, Dynamic KL Loss: 1.419233072478379e+20, Representation loss : 1.419233072478379e+20\n",
      "Total Loss of 312: 2.2859583328354304e+16, Recon Loss: 914432917504.0, Reward Loss: 499956736.0, Continue Loss: 0.7662972211837769, Dynamic KL Loss: 1.142933472260653e+18, Representation loss : 1.142933472260653e+18\n",
      "Total Loss of 313: 5087484862005248.0, Recon Loss: 1777056743424.0, Reward Loss: 47410836.0, Continue Loss: 0.8363044261932373, Dynamic KL Loss: 2.5428539418555187e+17, Representation loss : 2.5428539418555187e+17\n",
      "Total Loss of 314: 3.886615714318411e+19, Recon Loss: 44709510643712.0, Reward Loss: 132118768.0, Continue Loss: 0.8081973195075989, Dynamic KL Loss: 1.943305631747671e+21, Representation loss : 1.943305631747671e+21\n",
      "Total Loss of 315: 5.78928262554583e+16, Recon Loss: 5831310966784.0, Reward Loss: 150525360.0, Continue Loss: 0.7350472211837769, Dynamic KL Loss: 2.8943500109110313e+18, Representation loss : 2.8943500109110313e+18\n",
      "Total Loss of 316: 3514530399256576.0, Recon Loss: 290599075840.0, Reward Loss: 454785632.0, Continue Loss: 0.7856758236885071, Dynamic KL Loss: 1.757119568024699e+17, Representation loss : 1.757119568024699e+17\n",
      "Total Loss of 317: 2583496111423488.0, Recon Loss: 598466560000.0, Reward Loss: 13624194048.0, Continue Loss: 0.8319401741027832, Dynamic KL Loss: 1.2914420339231949e+17, Representation loss : 1.2914420339231949e+17\n",
      "Total Loss of 318: 1.1144601755503821e+18, Recon Loss: 158541604192256.0, Reward Loss: 1114198656.0, Continue Loss: 0.7156686782836914, Dynamic KL Loss: 5.571508212331656e+19, Representation loss : 5.571508212331656e+19\n",
      "Total Loss of 319: 1.1564890934214656e+16, Recon Loss: 295528136704.0, Reward Loss: 140881088.0, Continue Loss: 0.7469186782836914, Dynamic KL Loss: 5.782297290735616e+17, Representation loss : 5.782297290735616e+17\n",
      "Total Loss of 320: 2.148338848144084e+19, Recon Loss: 54298071269376.0, Reward Loss: 522030784.0, Continue Loss: 0.7587900757789612, Dynamic KL Loss: 1.0741667060792982e+21, Representation loss : 1.0741667060792982e+21\n",
      "Total Loss of 321: 1.4259370879614976e+16, Recon Loss: 1057954791424.0, Reward Loss: 542364992.0, Continue Loss: 0.718811571598053, Dynamic KL Loss: 7.12915642868564e+17, Representation loss : 7.12915642868564e+17\n",
      "Total Loss of 322: 1.326984906932224e+16, Recon Loss: 378582433792.0, Reward Loss: 156819952.0, Continue Loss: 0.7931829690933228, Dynamic KL Loss: 6.634734911855002e+17, Representation loss : 6.634734911855002e+17\n",
      "Total Loss of 323: 6.550247063987159e+18, Recon Loss: 200909376192512.0, Reward Loss: 702707840.0, Continue Loss: 0.8319401144981384, Dynamic KL Loss: 3.275023278523359e+20, Representation loss : 3.275023278523359e+20\n",
      "Total Loss of 324: 1.5864788852670464e+16, Recon Loss: 5219729014784.0, Reward Loss: 188702608.0, Continue Loss: 0.7231758236885071, Dynamic KL Loss: 7.929784374709453e+17, Representation loss : 7.929784374709453e+17\n",
      "Total Loss of 325: 5.842798192931897e+18, Recon Loss: 433884609118208.0, Reward Loss: 38948256.0, Continue Loss: 0.8363044261932373, Dynamic KL Loss: 2.9211823167534164e+20, Representation loss : 2.9211823167534164e+20\n",
      "Total Loss of 326: 1.953645520459137e+18, Recon Loss: 18630708297728.0, Reward Loss: 1082599552.0, Continue Loss: 0.781311571598053, Dynamic KL Loss: 9.768134308734068e+19, Representation loss : 9.768134308734068e+19\n",
      "Total Loss of 327: 2.2851906074312704e+16, Recon Loss: 2191049490432.0, Reward Loss: 252816928.0, Continue Loss: 0.656311571598053, Dynamic KL Loss: 1.1424858335891948e+18, Representation loss : 1.1424858335891948e+18\n",
      "Total Loss of 328: 39715529031680.0, Recon Loss: 18206892032.0, Reward Loss: 151470624.0, Continue Loss: 0.7156686782836914, Dynamic KL Loss: 1984858469433344.0, Representation loss : 1984858469433344.0\n",
      "Total Loss of 329: 2.7222969453379584e+16, Recon Loss: 530023776256.0, Reward Loss: 822529408.0, Continue Loss: 0.7619329690933228, Dynamic KL Loss: 1.361122002785534e+18, Representation loss : 1.361122002785534e+18\n",
      "Total Loss of 330: 3.3214498051624796e+19, Recon Loss: 982488130256896.0, Reward Loss: 335294592.0, Continue Loss: 0.781311571598053, Dynamic KL Loss: 1.6606757632075712e+21, Representation loss : 1.6606757632075712e+21\n",
      "Total Loss of 331: 2459117885063168.0, Recon Loss: 320283803648.0, Reward Loss: 162503520.0, Continue Loss: 0.8363044261932373, Dynamic KL Loss: 1.2293986543520973e+17, Representation loss : 1.2293986543520973e+17\n",
      "Total Loss of 332: 8.039302467344663e+18, Recon Loss: 455453632888832.0, Reward Loss: 346084800.0, Continue Loss: 0.8513187170028687, Dynamic KL Loss: 4.019423612775149e+20, Representation loss : 4.019423612775149e+20\n",
      "Total Loss of 333: 5.286682715827911e+20, Recon Loss: 1.4017508386275328e+16, Reward Loss: 313876512.0, Continue Loss: 0.843811571598053, Dynamic KL Loss: 2.643271383234745e+22, Representation loss : 2.643271383234745e+22\n",
      "Total Loss of 334: 3.3912457037820723e+19, Recon Loss: 912399095824384.0, Reward Loss: 1143969664.0, Continue Loss: 0.7888187170028687, Dynamic KL Loss: 1.695577252944809e+21, Representation loss : 1.695577252944809e+21\n",
      "Total Loss of 335: 4.3069220110509015e+18, Recon Loss: 11604934524928.0, Reward Loss: 55341780.0, Continue Loss: 0.8050544261932373, Dynamic KL Loss: 2.153455271572312e+20, Representation loss : 2.153455271572312e+20\n",
      "Total Loss of 336: 1.4462374656344064e+16, Recon Loss: 1486345076736.0, Reward Loss: 1553824896.0, Continue Loss: 0.7619329690933228, Dynamic KL Loss: 7.230443439836365e+17, Representation loss : 7.230443439836365e+17\n",
      "Total Loss of 337: 1.0276846563019981e+18, Recon Loss: 3949446561792.0, Reward Loss: 1203257600.0, Continue Loss: 0.7037972211837769, Dynamic KL Loss: 5.138403545276272e+19, Representation loss : 5.138403545276272e+19\n",
      "Total Loss of 338: 2005830526304256.0, Recon Loss: 165539921920.0, Reward Loss: 262954832.0, Continue Loss: 0.7113044261932373, Dynamic KL Loss: 1.0028324293391155e+17, Representation loss : 1.0028324293391155e+17\n",
      "Total Loss of 339: 8.071285336451318e+17, Recon Loss: 122293078458368.0, Reward Loss: 14199656.0, Continue Loss: 0.8631901741027832, Dynamic KL Loss: 4.035031312272825e+19, Representation loss : 4.035031312272825e+19\n",
      "Total Loss of 340: 3563945340174336.0, Recon Loss: 551242629120.0, Reward Loss: 68160424.0, Continue Loss: 0.8169258236885071, Dynamic KL Loss: 1.7816970888793293e+17, Representation loss : 1.7816970888793293e+17\n",
      "Total Loss of 341: 1332538568081408.0, Recon Loss: 78122917888.0, Reward Loss: 111044144.0, Continue Loss: 0.7306829690933228, Dynamic KL Loss: 6.662301729947648e+16, Representation loss : 6.662301729947648e+16\n",
      "Total Loss of 342: 3.1426522820070343e+19, Recon Loss: 368906954866688.0, Reward Loss: 121318432.0, Continue Loss: 0.7619329690933228, Dynamic KL Loss: 1.5713077395769147e+21, Representation loss : 1.5713077395769147e+21\n",
      "Total Loss of 343: 3.617556893637018e+16, Recon Loss: 4354667708416.0, Reward Loss: 414217792.0, Continue Loss: 0.7231758236885071, Dynamic KL Loss: 1.8085607005665362e+18, Representation loss : 1.8085607005665362e+18\n",
      "Total Loss of 344: 2660523128651776.0, Recon Loss: 132409475072.0, Reward Loss: 491165856.0, Continue Loss: 0.9019473195075989, Dynamic KL Loss: 1.3301950943382733e+17, Representation loss : 1.3301950943382733e+17\n",
      "Total Loss of 345: 2.6854961623072768e+17, Recon Loss: 22061380534272.0, Reward Loss: 116007528.0, Continue Loss: 0.7931829690933228, Dynamic KL Loss: 1.3426378379330847e+19, Representation loss : 1.3426378379330847e+19\n",
      "Total Loss of 346: 5.42680319124308e+17, Recon Loss: 1262132658176.0, Reward Loss: 114457808.0, Continue Loss: 0.7619329690933228, Dynamic KL Loss: 2.713395465844215e+19, Representation loss : 2.713395465844215e+19\n"
     ]
    }
   ],
   "source": [
    "trainer.train(data_loader=dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count - 1 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 2 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 3 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 4 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 5 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 6 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 7 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 8 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 9 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 10 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 11 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 12 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 13 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 14 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 15 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 16 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 17 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 18 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 19 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 20 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 21 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 22 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 23 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 24 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 25 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 26 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 27 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 28 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 29 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 30 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 31 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 32 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 33 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 34 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 35 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 36 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 37 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 38 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 39 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 40 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 41 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 42 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 43 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 44 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 45 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 46 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 47 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 48 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 49 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 50 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 51 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 52 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 53 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 54 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 55 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 56 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 57 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 58 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 59 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 60 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 61 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 62 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 63 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 64 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 65 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 66 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 67 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 68 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 69 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 70 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 71 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 72 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 73 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 74 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 75 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 76 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 77 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 78 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 79 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 80 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 81 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 82 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 83 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 84 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 85 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 86 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 87 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 88 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 89 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 90 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 91 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 92 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 93 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 94 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 95 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 96 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 97 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 98 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 99 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 100 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 101 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 102 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 103 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 104 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 105 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 106 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 107 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 108 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 109 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 110 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 111 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 112 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 113 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 114 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 115 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 116 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 117 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 118 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 119 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 120 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 121 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 122 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 123 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 124 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 125 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 126 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 127 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 128 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 129 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 130 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 131 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 132 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 133 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 134 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 135 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 136 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 137 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 138 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 139 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 140 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 141 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 142 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 143 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 144 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 145 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 146 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 147 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 148 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 149 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 150 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 151 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 152 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 153 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 154 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 155 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 156 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 157 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 158 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 159 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 160 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 161 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 162 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 163 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 164 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 165 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 166 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 167 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 168 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 169 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 170 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 171 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 172 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 173 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 174 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 175 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 176 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 177 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 178 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 179 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 180 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 181 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 182 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 183 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 184 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 185 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 186 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 187 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 188 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 189 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 190 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 191 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 192 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 193 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 194 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 195 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 196 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 197 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 198 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 199 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 200 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 201 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 202 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 203 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 204 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 205 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 206 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 207 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 208 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 209 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 210 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 211 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 212 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 213 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 214 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 215 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 216 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 217 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 218 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 219 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 220 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 221 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 222 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 223 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 224 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 225 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 226 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 227 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 228 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 229 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 230 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 231 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 232 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 233 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 234 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 235 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 236 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 237 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 238 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 239 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 240 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 241 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 242 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 243 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 244 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 245 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 246 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 247 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 248 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 249 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 250 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 251 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 252 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 253 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 254 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 255 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 256 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 257 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 258 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 259 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 260 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 261 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 262 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 263 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 264 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 265 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 266 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 267 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 268 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 269 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 270 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 271 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 272 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 273 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 274 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 275 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 276 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 277 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 278 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 279 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 280 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 281 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 282 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 283 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 284 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 285 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 286 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 287 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 288 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 289 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 290 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 291 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 292 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 293 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 294 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 295 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 296 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 297 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 298 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 299 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 300 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 301 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 302 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 303 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 304 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 305 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 306 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 307 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 308 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 309 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 310 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 311 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 312 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 313 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 314 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 315 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 316 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 317 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 318 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 319 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 320 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 321 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 322 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 323 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 324 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 325 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 326 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 327 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 328 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 329 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 330 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 331 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 332 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 333 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 334 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 335 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 336 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 337 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 338 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 339 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 340 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 341 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 342 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 343 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 344 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 345 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n",
      "Count - 346 -- > obs : torch.Size([32, 467]) - reward : torch.Size([32]) - actions : torch.Size([32, 179]) - dones : torch.Size([32]) - next_obs : torch.Size([32, 467])\n"
     ]
    }
   ],
   "source": [
    "for loop_count, (obs, rewards, actions, dones, next_obs) in enumerate(dataloader, start=1):  \n",
    "    print(f\"Count - {loop_count} -- > obs : {obs.shape} - reward : {rewards.shape} - actions : {actions.shape} - dones : {dones.shape} - next_obs : {next_obs.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "l2rpn-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
